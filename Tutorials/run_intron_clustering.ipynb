{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "# still do preprocessing in scipy\n",
    "import scipy.sparse as sp\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from importlib import reload\n",
    "# get UMAP\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "# import factor model from beta-dirichlet-factor\n",
    "sys.path.append('/gpfs/commons/home/kisaev/Leaflet-private/src/beta-binomial-mix')\n",
    "import betabinomo_mix_singlecells as bbmix\n",
    "import cell_state_asign_consistency as cellassign\n",
    "\n",
    "reload(bbmix)\n",
    "reload(cellassign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append this directory to sys.path\n",
    "sys.path.append('/gpfs/commons/home/kisaev/Leaflet-private/src/clustering/')\n",
    "import Leaflet_load_cluster_data_03 as llc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse mammary gland data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ=\"Liver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load any metadata that is available so that we can run differential splicing analysis between specific cell types\n",
    "adata = sc.read_h5ad(\"/gpfs/commons/datasets/controlled/CZI/tabula-sapiens/TS_figshare/TabulaSapiens.h5ad\")\n",
    "metadata = adata.obs \n",
    "# filter first by organ_tissue\n",
    "metadata = metadata[metadata[\"organ_tissue\"]==organ]\n",
    "metadata = metadata[[\"organ_tissue\", \"free_annotation\", \"cell_ontology_class\", \"compartment\"]].drop_duplicates()\n",
    "# drop index \n",
    "metadata = metadata.reset_index(drop=True)\n",
    "# rename cell_ontology_class to cell_type \n",
    "metadata = metadata.rename(columns={\"cell_ontology_class\" : \"cell_type\"})\n",
    "metadata.head()\n",
    "\n",
    "use_metadata = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to cuda if available \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# set float type to torch.float to save memory\n",
    "float_type = { \n",
    "    \"device\" : device, \n",
    "    \"dtype\" : torch.float, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_folder = '/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/TabulaMurisBrain/MLCB_Brain_true/FULL/'\n",
    "\n",
    "# convert data to Leaflet required input formats \n",
    "final_data, coo_counts_sparse, coo_cluster_sparse, cell_ids_conversion, junction_ids_conversion = llc.load_cluster_data(\n",
    "    input_folder = input_files_folder, max_intron_count=10000, remove_singletons=True, has_genes=\"yes\") #, celltypes=cell_types) \n",
    "\n",
    "# add cluster to final_data \n",
    "final_data = final_data.merge(junction_ids_conversion, on=[\"junction_id_index\"], how=\"left\")\n",
    "cell_index_tensor, junc_index_tensor, my_data = llc.make_torch_data(final_data, **float_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"cell_type\"] = metadata[\"free_annotation\"]\n",
    "\n",
    "# merge cell_ids_conversion with metadata to add more cell type information\n",
    "if use_metadata is True:\n",
    "    cell_ids_conversion = cell_ids_conversion.merge(metadata, on=\"cell_type\")\n",
    "\n",
    "simple_data_human = final_data[[\"cell_id_index\", \"Cluster\", \"cell_type\", \"junction_id_index\", \"juncratio\", \"junc_count\", \"cluster_count\",  \"junction_id\", \"gene_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of junctions is: \", len(junction_ids_conversion))\n",
    "print(\"The number of intron clusters observed is: \", len(junction_ids_conversion.Cluster.unique()))\n",
    "print(\"The number of genes is: \", len(junction_ids_conversion.gene_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_index_tensor, junc_index_tensor, my_data = llc.make_torch_data(final_data, **float_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids_conversion['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Binomial mixture model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "K = len(cell_ids_conversion.cell_type.unique())\n",
    "\n",
    "hypers = {\n",
    "    \"eta\" : 1./K, \n",
    "    \"alpha_prior\" : 1., \n",
    "    \"pi_prior\" : 1.\n",
    "}\n",
    "\n",
    "print(hypers[\"eta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_labels = cell_ids_conversion[\"cell_type\"]\n",
    "# Set GAMMA to dummy values based on the initial labels\n",
    "cell_type_dummy = pd.get_dummies(init_labels)\n",
    "cell_type_dummy_columns = cell_type_dummy.columns\n",
    "# make dataframe of cell_type_dummy_columns and index from 0 to len(cell_type_dummy_columns)\n",
    "cell_type_dummy_df = pd.DataFrame(cell_type_dummy_columns, columns=[\"cell_type\"])\n",
    "cell_type_dummy_df[\"cell_type_index\"] = range(len(cell_type_dummy_columns))\n",
    "# we will just save this here for now and run CAVI and map everything back after before doing differential splicing analysis \n",
    "cell_type_dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bbmix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1 # should also be an argument that gets fed in\n",
    "num_iters = 100 # should also be an argument that gets fed in\n",
    "tol = 0.0001\n",
    "print(\"The K used is: \", K)\n",
    "results = [ bbmix.calculate_CAVI(K, my_data, float_type, hypers, init_labels = init_labels, num_iterations = num_iters, fixed_cell_types = True, tolerance=tol) \n",
    "           for t in range(num_trials) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_matrices = cellassign.consensus_clustering(results)\n",
    "\n",
    "# normalize by number of trials\n",
    "normalized_matrix = sum_matrices / sum_matrices.max() # taking the sum_matrix and dividing by the max value in the matrix\n",
    "\n",
    "# get distance metric \n",
    "distance_matrix = 1 - normalized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap \n",
    "\n",
    "num_samples = 1000\n",
    "samp_indices = np.random.choice(cell_ids_conversion.shape[0], num_samples, replace=False)\n",
    "cell_types_heatmap = cell_ids_conversion.iloc[samp_indices]\n",
    "\n",
    "color_palette = sns.color_palette(\"Set1\", n_colors=len(cell_types_heatmap['cell_type'].unique()))\n",
    "\n",
    "# Create a color bar legend\n",
    "legend = sns.color_palette(palette=color_palette, as_cmap=True)\n",
    "\n",
    "# Obtain cell type labels for every cell in the matrix also \n",
    "unique_cell_types = cell_types_heatmap['cell_type'].unique()\n",
    "num_unique_types = len(unique_cell_types)\n",
    "colors = sns.color_palette('Set1', n_colors=num_unique_types)  # You can use any color palette\n",
    "cell_types = cell_types_heatmap.cell_type.values\n",
    "\n",
    "cell_type_colors = dict(zip(unique_cell_types, colors))\n",
    "\n",
    "# Convert cell types to corresponding colors for rows and columns\n",
    "row_colors = [cell_type_colors[cell_type] for cell_type in cell_types]\n",
    "col_colors = [cell_type_colors[cell_type] for cell_type in cell_types]\n",
    "\n",
    "cluster = sns.clustermap(\n",
    "    data=sum_matrices[samp_indices,:][:,samp_indices],\n",
    "    method='complete',\n",
    "    cmap=\"viridis\",\n",
    "    annot=False,\n",
    "    fmt=\".2f\",\n",
    "    xticklabels=False,\n",
    "    yticklabels=False,\n",
    "    figsize=(8, 8),\n",
    "    center=0,\n",
    "    row_colors=row_colors,  # Apply row colors\n",
    "    col_colors=col_colors,   # Apply column colors\n",
    "        cbar_kws={'label': 'Number of trials'} # Split label over two lines here\n",
    "    )\n",
    "\n",
    "cluster.cax.set_ylabel('Number of trials', size=16)\n",
    "# Increase font size for color bar tick labels:\n",
    "cbar_ax = cluster.cax\n",
    "for label in cbar_ax.yaxis.get_ticklabels():\n",
    "    label.set_size(16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "\n",
    "# Create the legend\n",
    "for cell_type, color in cell_type_colors.items():\n",
    "    plt.plot([], [], 'o', label=cell_type, color=color, markersize=27)  # Use 'o' to show the colors clearly\n",
    "\n",
    "plt.legend(fontsize=20)\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the learned posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.argmax([ g[-1][-1] for g in results ]) # final ELBO\n",
    "print(f\"The trial with the highest ELBO was {best}\")\n",
    "ALPHA_f, PI_f, GAMMA_f, PHI_f, elbos_all = results[best]\n",
    "elbos_all = np.array(elbos_all)\n",
    "plt.plot(elbos_all[1:]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHI_f_plot = pd.DataFrame(PHI_f.cpu().numpy())\n",
    "PHI_f_plot['cell_id'] = cell_ids_conversion[\"cell_type\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(PHI_f.flatten())\n",
    "# make histogram of the cell type proportions\n",
    "plt.hist(np.array(PHI_f.flatten()), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much is each cell state is used globally \n",
    "\n",
    "# Calculate the total sum of the tensor values\n",
    "total_sum = torch.sum(GAMMA_f)\n",
    "\n",
    "# Calculate the percentages\n",
    "percentages = (GAMMA_f / total_sum) \n",
    "print(percentages)\n",
    "\n",
    "# Convert the tensor to a dataframe \n",
    "GAMMA_f_plot = pd.DataFrame(percentages.cpu().numpy())\n",
    "# Give it a colname called theta \n",
    "GAMMA_f_plot.columns = [\"theta\"]\n",
    "GAMMA_f_plot[\"cell_state\"] = GAMMA_f_plot.index\n",
    "GAMMA_f_plot.sort_values(by=\"theta\", ascending=False, inplace=True)\n",
    "GAMMA_f_plot[\"new_cell_state\"] = np.arange(GAMMA_f_plot.shape[0])\n",
    "\n",
    "sorted_cell_states = GAMMA_f_plot[\"new_cell_state\"].astype(str)\n",
    "\n",
    "# rename cell_state to be from 0 to K-1 based on order in sorted_cell_states\n",
    "GAMMA_f_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA_f_plot[\"new_cell_state\"] = pd.Categorical(sorted_cell_states, sorted_cell_states.unique())\n",
    "GAMMA_f_plot = GAMMA_f_plot.sort_values(by='new_cell_state')\n",
    "\n",
    "# Create a color mapping for each unique cellassignment\n",
    "unique_states = GAMMA_f_plot['new_cell_state'].unique()\n",
    "palette = sns.color_palette(\"colorblind\", len(unique_states))\n",
    "color_mapping = dict(zip(unique_states, palette))\n",
    "\n",
    "# Make barplot using sns\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.barplot(x=\"new_cell_state\", y=\"theta\", data=GAMMA_f_plot, palette=color_mapping)\n",
    "plt.axhline(0.005, ls='--', color='grey')\n",
    "\n",
    "# Make Y label say Theta and increase font of all labels and ticks\n",
    "plt.ylabel(\"Theta\", fontsize=23)\n",
    "plt.xlabel(\"Learned Cell States (K)\", fontsize=23)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types_summary=cell_ids_conversion['cell_type'].value_counts()\n",
    "cell_types_summary=pd.DataFrame(cell_types_summary)\n",
    "cell_types_summary.reset_index(inplace=True)\n",
    "cell_types_summary.columns=['cell_type','count']\n",
    "\n",
    "# get percentage of each cell type in the data \n",
    "cell_types_summary['percentage']=cell_types_summary['count']/cell_types_summary['count'].sum()\n",
    "cell_types_summary.sort_values(by='percentage',ascending=False,inplace=True)\n",
    "print(cell_types_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the barplot using the cell_type_colors palette\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.barplot(x=\"cell_type\", y=\"percentage\", data=cell_types_summary)\n",
    "plt.axhline(0.005, ls='--', color='grey')\n",
    "plt.ylabel(\"Percentage\", fontsize=23)\n",
    "plt.xlabel(\"Observed Cell Types\", fontsize=23)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's retain only the cell states that are used more than 1% of the time\n",
    "#GAMMA_f_plot = GAMMA_f_plot[GAMMA_f_plot[\"theta\"] > 0.005]\n",
    "#GAMMA_f_plot.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PHI_f to a dataframe and add a column with cell ID and cell type \n",
    "PHI_f = pd.DataFrame(PHI_f)\n",
    "\n",
    "# Keep only cell states defined above GAMMA_f_plot.index.values\n",
    "PHI_f = PHI_f.loc[:, GAMMA_f_plot.index.values]\n",
    "PHI_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"CellState\" to each column \n",
    "PHI_f.columns = [\"CellState_\" + str(i+1) for i in range(PHI_f.shape[1])]\n",
    "PHI_f['cell_id'] = cell_ids_conversion.cell_id.values\n",
    "PHI_f['cell_type'] = cell_ids_conversion.cell_type.values\n",
    "PHI_f.groupby('cell_type').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by cell_type and sum across each cellstate \n",
    "PHI_f.groupby('cell_type').sum()\n",
    "sum_prop=PHI_f.groupby('cell_type').sum()/PHI_f.groupby('cell_type').count()\n",
    "# remove cell_id column \n",
    "sum_prop=sum_prop.drop(columns=['cell_id'])\n",
    "#masked_data = np.ma.masked_equal(sum_prop, 0)\n",
    "sns.set(font_scale=0.8)  # Adjust font size for labels\n",
    "# make figure bigger \n",
    "plt.figure(figsize=(6, 6))\n",
    "# make font size of xtickts and yticks bigger\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "\n",
    "ax = sns.heatmap(sum_prop, annot=True, cmap=\"YlGnBu\", fmt='.2f', annot_kws={\"size\": 10}, cbar_kws={'label': 'Percentage of Cells'})\n",
    "\n",
    "#labels = [label.get_text().replace(\"oligodendrocyte_precursor_cell\", \"oligodendrocyte_\\nprecursor_cell\") for label in ax.get_yticklabels()]\n",
    "#ax.set_yticklabels(labels)\n",
    "\n",
    "# Further visual modifications\n",
    "xlabel = plt.xlabel(\"Cell States\", fontsize=16)\n",
    "ylabel = plt.ylabel(\"Cell Types\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Adjusting color bar settings\n",
    "cbar = plt.gcf().axes[-1]\n",
    "cbar.tick_params(labelsize=13)\n",
    "cbar.set_ylabel('Percentage of Cells', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run fisher's exact test to see if the cell states are enriched for any cell types\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "PHI_f_melt = pd.melt(PHI_f, id_vars=['cell_id', 'cell_type'], value_vars=PHI_f.columns[:-2])\n",
    "\n",
    "# for each cell, choose cell state with highest probability\n",
    "PHI_f_melt = PHI_f_melt.sort_values(by=['cell_id', 'value'], ascending=False).drop_duplicates(subset=['cell_id'])\n",
    "PHI_f_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run fisher's exact test to test overall association between cell states and cell types\n",
    "# contingency table\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = pd.crosstab(PHI_f_melt['variable'], PHI_f_melt['cell_type'])\n",
    "contingency_table\n",
    "\n",
    "chi2, pvalue, _, _ = chi2_contingency(contingency_table)\n",
    "print(chi2, pvalue)\n",
    "print(print(\"P-value: {:.50f}\".format(pvalue)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names to only include cell type the thing aftert 'Myeloid_'\n",
    "#contingency_table.columns = ['_'.join(x.split('_')[2:]) for x in contingency_table.columns]\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert contingency table to proportions \n",
    "contingency_table = contingency_table / contingency_table.sum() # represents proportion of cells in cell type that is in cell state \n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder variable in contingency table cellstate10 should go after cellstate9\n",
    "contingency_table = contingency_table.reindex(sorted(contingency_table.columns), axis=1)\n",
    "\n",
    "ordered_indices = [\n",
    "    'CellState_1', 'CellState_2', 'CellState_3', 'CellState_4',\n",
    "    'CellState_5']\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "#ordered_indices = [\n",
    "#    'CellState_1', 'CellState_2', 'CellState_3', 'CellState_4',\n",
    "#    'CellState_5', 'CellState_6', 'CellState_7', 'CellState_8',\n",
    "#    'CellState_9', 'CellState_10'\n",
    "#]\n",
    "\n",
    "contingency_table = contingency_table.reindex(ordered_indices)\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.heatmap(contingency_table.T, annot=True, cmap=\"YlGnBu\", fmt='.2f', annot_kws={\"size\": 10}, cbar_kws={'label': 'Percentage of Cells'})\n",
    "\n",
    "# Further visual modifications\n",
    "xlabel = plt.xlabel(\"Cell States\", fontsize=16)\n",
    "ylabel = plt.ylabel(\"Cell Types\", fontsize=16)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Adjusting color bar settings\n",
    "cbar = plt.gcf().axes[-1]\n",
    "cbar.tick_params(labelsize=13)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table\n",
    "\n",
    "# plot clustermap of contingency table\n",
    "g = sns.clustermap(contingency_table.T, cmap=\"YlGnBu\", figsize=(8, 6), annot=True, fmt='.2f', annot_kws={\"size\": 10}, cbar_kws={'label': '% of cells'})\n",
    "# Increase the font size of the x-axis and y-axis tick labels\n",
    "plt.setp(g.ax_heatmap.get_xticklabels(), fontsize=12) # Set x-axis label size\n",
    "plt.setp(g.ax_heatmap.get_yticklabels(), fontsize=12) # Set y-axis label size\n",
    "# remove x lab \n",
    "g.ax_heatmap.set_xlabel(\"\")\n",
    "\n",
    "# Save the figure to a PDF file\n",
    "plt.savefig(\"clustermap.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential junction usage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leafcutter-sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
