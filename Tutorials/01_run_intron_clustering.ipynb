{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run intron clustering to annotate alternative splicing events given observed junctions in our cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The junctions are loaded from the following path: /gpfs/commons/home/kisaev/LeafletSC/data/raw/junctions/\n",
      "The files in the path are: ['B107926_O8_Blue_Blood_S250.homo.gencode.v30.ERCC.chrM.juncswbarcodes', 'B107925_B5_S284.homo.gencode.v30.ERCC.chrM.juncswbarcodes']\n"
     ]
    }
   ],
   "source": [
    "# Load LeafletSC \n",
    "import LeafletSC\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "# Define path that contains some junction files (only 2 files are used for this example, corresponding to 2 individual cells)\n",
    "juncs_path = \"/gpfs/commons/home/kisaev/LeafletSC/data/raw/junctions/\"\n",
    "print(\"The junctions are loaded from the following path: \" + juncs_path) \n",
    "\n",
    "# print the files in the path \n",
    "print(\"The files in the path are: \" + str(os.listdir(juncs_path)))\n",
    "\n",
    "# define path for saving the output data \n",
    "output_path = \"/gpfs/commons/home/kisaev/LeafletSC/data/processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first define some parameters for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LeafletSC.clustering.find_intron_clusters import main as find_intron_clusters\n",
    "from LeafletSC.clustering.prepare_model_input import main as prep_model_input\n",
    "\n",
    "# junc_files defines a path for where junction files can be found, in this case, the path is defined above\n",
    "junc_files = juncs_path\n",
    "\n",
    "# we provide a gtf file for the human genome as well to make better sense of the junctions that are detected in cells\n",
    "# please replace with the path to the gtf file on your system\n",
    "gtf_file=\"/gpfs/commons/groups/knowles_lab/Karin/genome_files/gencode.v43.basic.annotation.gtf\" \n",
    "\n",
    "# define additional parameters \n",
    "sequencing_type = \"single_cell\"\n",
    "\n",
    "# ensure output files are to be saved in output_path \n",
    "output_file = output_path + \"test_intron_clusters\"\n",
    "junc_bed_file= output_path + \"test_juncs.bed\" # you can load this file into IGV to visualize the junction coordinates \n",
    "min_intron_length = 50\n",
    "max_intron_length = 500000\n",
    "threshold_inc = 0.05 \n",
    "min_junc_reads = 2\n",
    "min_num_cells_wjunc = 2\n",
    "keep_singletons = False # ignore junctions that do not share splice sites with any other junction (likely const)\n",
    "junc_suffix = \"*.juncswbarcodes\" # depends on how you ran regtools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run intron clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in junction files from /gpfs/commons/home/kisaev/LeafletSC/data/raw/junctions\n",
      "The number of junction files to be processed is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 20.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gtf file you provided is /gpfs/commons/groups/knowles_lab/Karin/genome_files/gencode.v43.basic.annotation.gtf\n",
      "This step may take a while depending on the size of your gtf file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'tag', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'havana_transcript', 'exon_number', 'exon_id', 'hgnc_id', 'havana_gene', 'ont', 'protein_id', 'ccdsid', 'artif_dupl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gtf file took 57.08 seconds\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "The number of unique exons is 411865\n",
      "The number of unique transcript ids is 115526\n",
      "The number of unique gene ids is 62668\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Done extracting exons from gtf file\n",
      "Loading files obtained from single_cell sequencing\n",
      "Cleaning up 'chrom' column\n",
      "Making gr object from all junctions across all cell types\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'counts_total'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'counts_total'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_juncs_df \u001b[38;5;241m=\u001b[39m \u001b[43mfind_intron_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjunc_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjunc_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgtf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msequencing_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequencing_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjunc_bed_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjunc_bed_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mthreshold_inc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_inc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_intron\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_intron_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmax_intron\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_intron_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_junc_reads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_junc_reads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msingleton\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_singletons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mjunc_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjunc_suffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_num_cells_wjunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_num_cells_wjunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_notebook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/LeafletSC/clustering/find_intron_clusters.py:438\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(junc_files, gtf_file, output_file, sequencing_type, junc_bed_file, threshold_inc, min_intron, max_intron, min_junc_reads, singleton, junc_suffix, min_num_cells_wjunc, run_notebook)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# 7. Make gr object from ALL junctions across all cell types \u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking gr object from all junctions across all cell types\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 438\u001b[0m juncs_gr \u001b[38;5;241m=\u001b[39m pr\u001b[38;5;241m.\u001b[39mfrom_dict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChromosome\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_juncs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchrom\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_juncs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromStart\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_juncs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromEnd\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStrand\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_juncs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrand\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_juncs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjunction_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_juncs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjunction_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounts_total\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mall_juncs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcounts_total\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m})\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# Unique set of junction coordinates across all samples (or cells) \u001b[39;00m\n\u001b[1;32m    440\u001b[0m juncs_gr \u001b[38;5;241m=\u001b[39m juncs_gr[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChromosome\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStrand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjunction_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounts_total\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicate_positions()\n",
      "File \u001b[0;32m~/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'counts_total'"
     ]
    }
   ],
   "source": [
    "all_juncs_df = find_intron_clusters(junc_files=junc_files, gtf_file=gtf_file, output_file=output_file, \n",
    "                       sequencing_type=sequencing_type, junc_bed_file=junc_bed_file, \n",
    "                       threshold_inc=threshold_inc, min_intron = min_intron_length,\n",
    "                       max_intron=max_intron_length, min_junc_reads=min_junc_reads,\n",
    "                       singleton=keep_singletons,\n",
    "                       junc_suffix=junc_suffix, min_num_cells_wjunc=min_num_cells_wjunc,\n",
    "                       run_notebook = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize junctions in an intron cluster \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's convert the intron clusters to a format that can be used by LeafletSC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intron_clusters = \"/gpfs/commons/home/kisaev/LeafletSC/data/processed/test_intron_clusters_50_500000_2_20240309_single_cell.gz\" # path to the intron clusters file\n",
    "output_file = output_path + \"test_model_input\" # name of the output file\n",
    "has_genes = \"yes\" # since we used a gtf file to obtain the intron clusters, we can set this to yes\n",
    "chunk_size = 5000 # number of junctions to process at a time from the intron clusters files\n",
    "metadata = None # can replace with path, if metadata is available for cells (cell type, origin, library ID...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_model_input.main(intron_clusters, output_file, has_genes, chunk_size, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a quick look at the input file that will go into the model to get familiarized with all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_data = \"/gpfs/commons/home/kisaev/LeafletSC/data/processed/test_model_input.h5\"\n",
    "summarized_data = pd.read_hdf(model_input_data, 'df')\n",
    "print(summarized_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that fow now, the values in cell_type default to the cell's path, in the future it will be possible to specify the cell type in the metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_data.cell_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see all the columns in the summarized data\n",
    "print(summarized_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can quickly visualize the overall junction usage ratio distribution across all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarized_data.junc_ratio.hist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have everything need to run the Leaflet mixture model! Please refer to the next notebook for the next steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leafcutter-sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
