{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import itertools\n",
    "from io import BytesIO\n",
    "import tqdm\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the clustered data /gpfs/commons/groups/knowles_lab/Karin/data/GTEx/clustered_junctions.h5\n",
    "clusts = pd.read_hdf(\"/gpfs/commons/groups/knowles_lab/Karin/data/GTEx/clustered_junctions_minjunccounts.h5\", key='df') # these have start-1 coordinates compared to original GTEx matrix\n",
    "\n",
    "# make Name column to match GTEx file by first need to add \"chr\" before Chromosome column and subtract 1 from Start column \n",
    "clusts[\"Name\"] = \"chr\" + clusts[\"Chromosome\"].astype(str) + \"_\" + (clusts[\"Start\"]+1).astype(str) + \"_\" + clusts[\"End\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>junction_id</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>169795213</td>\n",
       "      <td>169798918</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>1_169795214_169798918</td>\n",
       "      <td>C1orf112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>chr1_169795214_169798918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>169806088</td>\n",
       "      <td>169807790</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>1_169806089_169807790</td>\n",
       "      <td>C1orf112</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>chr1_169806089_169807790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>169807929</td>\n",
       "      <td>169821678</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>1_169807930_169821678</td>\n",
       "      <td>C1orf112</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>chr1_169807930_169821678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>169821759</td>\n",
       "      <td>169823407</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>1_169821760_169823407</td>\n",
       "      <td>C1orf112</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>chr1_169821760_169823407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>169823472</td>\n",
       "      <td>169827050</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>1_169823473_169827050</td>\n",
       "      <td>C1orf112</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>chr1_169823473_169827050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Chromosome      Start        End Strand          gene_id  \\\n",
       "0          1  169795213  169798918      +  ENSG00000000460   \n",
       "1          1  169806088  169807790      +  ENSG00000000460   \n",
       "2          1  169807929  169821678      +  ENSG00000000460   \n",
       "3          1  169821759  169823407      +  ENSG00000000460   \n",
       "4          1  169823472  169827050      +  ENSG00000000460   \n",
       "\n",
       "             junction_id gene_name  Cluster  Count                      Name  \n",
       "0  1_169795214_169798918  C1orf112        1      1  chr1_169795214_169798918  \n",
       "1  1_169806089_169807790  C1orf112        2      1  chr1_169806089_169807790  \n",
       "2  1_169807930_169821678  C1orf112        3      1  chr1_169807930_169821678  \n",
       "3  1_169821760_169823407  C1orf112        4      1  chr1_169821760_169823407  \n",
       "4  1_169823473_169827050  C1orf112        5      1  chr1_169823473_169827050  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove singleton clusters where Count == 1\n",
    "clusts = clusts[clusts[\"Count\"] > 1]\n",
    "len(clusts.Name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order clusts by descending count\n",
    "clusts = clusts.sort_values(by=\"Count\", ascending=False)\n",
    "clusts.head()\n",
    "\n",
    "# remove clusters with more than 10 junctions\n",
    "clusts = clusts[clusts[\"Count\"] <= 10]\n",
    "len(clusts.Name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tot junc counts \n",
    "junc_counts = pd.read_csv(\"/gpfs/commons/groups/knowles_lab/Karin/data/GTEx/GTEx_juncs_total_counts.txt\", sep=\"\\t\")\n",
    "junc_counts.columns = [\"Name\", \"Junc_Counts\"]\n",
    "junc_counts = junc_counts.sort_values(by=\"Junc_Counts\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtex sample annotations \n",
    "samples = pd.read_csv(\"/gpfs/commons/groups/knowles_lab/Karin/data/GTEx/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt\", sep=\"\\t\")\n",
    "samples = samples[[\"SAMPID\", \"SMTS\", \"SMTSD\"]].drop_duplicates()\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe for each tissue type in SMTS column that has each sample ID and the tissue type with corresponding junctions and their counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts_simple = clusts[[\"Name\", \"Cluster\", \"gene_name\"]].drop_duplicates()\n",
    "# reset index in the dataframe\n",
    "clusts_simple = clusts_simple.reset_index(drop=True)\n",
    "clusts_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusts_simple.Cluster.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusts_simple.Name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample 500 Cluster IDs for a test run\n",
    "clusts_sample = clusts_simple.sample(n=50, random_state=1)\n",
    "print(len(clusts_sample.Cluster.unique()))\n",
    "print(len(clusts_sample.Name.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1*300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "gtex_juncs = '/gpfs/commons/groups/knowles_lab/Karin/data/GTEx/GTEx_Analysis_2017-06-05_v8_STARv2.5.3a_junctions.gct'\n",
    "\n",
    "class MeltedJunctions:\n",
    "    def __init__(self, file_name, clusts_names, clusts, samples):\n",
    "        self.file_name = file_name\n",
    "        self.clusts_names = clusts_names\n",
    "        self.clusts = clusts\n",
    "        self.samples = samples\n",
    "        \n",
    "    def melt_junctions(self):\n",
    "        melted_dfs = []\n",
    "        \n",
    "        # Read in the file as a Dask DataFrame\n",
    "        dask_df = dd.read_csv(self.file_name, sample=1000000, sep=\"\\t\")\n",
    "        \n",
    "        # Skip the first two rows\n",
    "        with open(self.file_name) as f:\n",
    "            #next(f)\n",
    "            #next(f)\n",
    "            header = f.readline().strip().split(\"\\t\")\n",
    "        \n",
    "        print(\"Number of samples in the file: \", len(header))\n",
    "        # Group the samples by tissue\n",
    "        samples_df = self.samples\n",
    "\n",
    "        # Keep only samples that are found in the header \n",
    "        samples_df = samples_df[samples_df['SAMPID'].isin(header)]\n",
    "        grouped_samples = samples_df.groupby('SMTS')['SAMPID'].apply(list)\n",
    "        # Iterate over the tissues and split the count matrix\n",
    "        print(\"Iterating over tissues...\")\n",
    "\n",
    "        # Let's also only keep the junctions in our clusts_names list\n",
    "        #dask_df = dask_df[dask_df['Name'].isin(self.clusts_names)] \n",
    "\n",
    "        for tissue, samples in grouped_samples.items():\n",
    "            print(\"Processing tissue: \", tissue)\n",
    "            # Get the column indices for the samples in the current tissue\n",
    "            sample_indices = [header.index(sample) for sample in samples]\n",
    "            print(\"Number of samples in the current tissue: \", str(len(sample_indices)))\n",
    "            # Extract the columns for the current tissue\n",
    "            tissue_df = dask_df.iloc[:, [0,1] + sample_indices]\n",
    "            print(\"HI\")\n",
    "            # Filter out the junctions that are not in our clusts_names list\n",
    "            tissue_df = tissue_df[tissue_df['Name'].isin(self.clusts_names)] \n",
    "            print(\"HI\")\n",
    "            # Add the tissue name as a column\n",
    "            tissue_df['Tissue'] = tissue\n",
    "            print(\"HI\")\n",
    "            # Extract the dataframe from dask \n",
    "            tissue_df = tissue_df.compute()\n",
    "            print(\"HI\")\n",
    "            # Merge with cluster info to get Cluster ID \n",
    "            tissue_df = tissue_df.merge(self.clusts, on=\"Name\", how=\"left\")\n",
    "            # Melt the dataframe\n",
    "            tissue_df = tissue_df.melt(id_vars=['Name', 'Description', 'Tissue', 'gene_name', 'Cluster'], var_name='Sample', value_name='Count')\n",
    "            # Remove rows with zero counts\n",
    "            tissue_df = tissue_df[tissue_df['Count'] > 0]\n",
    "            # Need to get total cluster counts for each sample-junction pair  (figure out how to do this later it's too much operation for single dask?)\n",
    "            #cluster_counts= tissue_df.groupby([\"Sample\", \"Cluster\"])[\"Count\"].sum().reset_index()\n",
    "            #cluster_counts.columns = ['Sample', 'Cluster', 'Cluster_Counts']    \n",
    "            #tissue_df = tissue_df.merge(clust_counts, on=[\"Sample\", \"Cluster\"], how=\"left\")\n",
    "            #print(cluster_counts.head())\n",
    "            melted_dfs.append(tissue_df)\n",
    "            #clust_counts.append(cluster_counts)\n",
    "        \n",
    "        print(\"Concatenating melted dataframes...\")\n",
    "        return melted_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the class with the file name and clusts names as arguments\n",
    "melted_junctions = MeltedJunctions(gtex_juncs, clusts_sample.Name, clusts_sample, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the melt_junctions method\n",
    "melted_df = melted_junctions.melt_junctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=melted_df[0].head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts= test.groupby([\"Sample\", \"Cluster\"])[\"Count\"].sum().reset_index()\n",
    "cluster_counts.columns = ['Sample', 'Cluster', 'Cluster_Counts']    \n",
    "cluster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.merge(cluster_counts, on=[\"Sample\", \"Cluster\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file and use as input for LDA script \n",
    "#summarized_data[\"junc_ratio\"] = summarized_data[\"junc_count\"] / summarized_data[\"Cluster_Counts\"]\n",
    "#summarized_data['sample_id_index'] = summarized_data.groupby('SAMPID').ngroup()\n",
    "#summarized_data['junction_id_index'] = summarized_data.groupby('Name').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_data.to_hdf(\"/gpfs/commons/groups/knowles_lab/Karin/data/GTEx/GTEx_junction_cluster_counts\" + \".h5\", key='df', mode='w', format=\"table\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leafcutter-sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
