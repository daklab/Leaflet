{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from load_cluster_data import load_cluster_data\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "float_type = { \n",
    "    \"device\" : device, \n",
    "    \"dtype\" : torch.float, # save memory\n",
    "}\n",
    "\n",
    "hypers = {\n",
    "    \"eta\" : 1., \n",
    "    \"alpha_prior\" : 1., # karin had 0.65 \n",
    "    \"pi_prior\" : 1.\n",
    "}\n",
    "\n",
    "K = 10\n",
    "\n",
    "import plotnine as p9\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt \n",
    "import splicing_PCA_utils\n",
    "from splicing_PCA_utils import make_Y\n",
    "from nuclear_norm_PCA import sparse_sum\n",
    "\n",
    "from pca_kmeans_init import pca_kmeans_init\n",
    "from betabinomo_LDA_singlecells_kinit import *\n",
    "import betabinomo_LDA_singlecells_kinit\n",
    "reload(betabinomo_LDA_singlecells_kinit)\n",
    "\n",
    "import plotnine as p9\n",
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap, geom_violin, theme\n",
    "import plotnine\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/gpfs/commons/scratch/kisaev/ss_tabulamuris_test/Leaflet/brain_mouse_cells_noanno.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../utils')\n",
    "PATH_TO_LEAFLET_REPO = '/gpfs/commons/home/kisaev/Leaflet/src/beta-binomial-mix/'\n",
    "sys.path.append(PATH_TO_LEAFLET_REPO)\n",
    "from load_cluster_data import load_cluster_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data from folder ...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'df_list' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_data, coo_counts_sparse, coo_cluster_sparse, cell_ids_conversion, junction_ids_conversion \u001b[39m=\u001b[39m load_cluster_data(\n\u001b[1;32m      2\u001b[0m     input_file)\u001b[39m#, celltypes = [\"Brain_Non-Myeloid_astrocyte_pseudobulk\", \"Brain_Non-Myeloid_endothelial_cell_pseudobulk\"])\u001b[39;00m\n",
      "File \u001b[0;32m~/Leaflet/src/beta-binomial-lda/load_cluster_data.py:33\u001b[0m, in \u001b[0;36mload_cluster_data\u001b[0;34m(input_file, input_folder, celltypes, num_cells_sample)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# concatenate all dataframes\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m summarized_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(df_list, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinished reading in data from folder ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39m#if want to look at only specific subset of cell types \u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'df_list' referenced before assignment"
     ]
    }
   ],
   "source": [
    "input_files_folder = '/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/TabulaMurisBrain/Brain/train/'\n",
    "\n",
    "final_data, coo_counts_sparse, coo_cluster_sparse, cell_ids_conversion, junction_ids_conversion = load_cluster_data(\n",
    "    input_folder = input_files_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still do preprocessing in scipy\n",
    "indices = (final_data.cell_id_index, final_data.junction_id_index)\n",
    "indices_np = np.stack(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junc_counts = sp.coo_matrix((final_data.junc_count, indices))\n",
    "cluster_counts = sp.coo_matrix((final_data.cluster_count, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data for nuc norm PCA\n",
    "Y_data, w = splicing_PCA_utils.make_Y(\n",
    "    junc_counts, cluster_counts, float_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn Y_data into COO matrix \n",
    "Y_data_coo = sp.coo_matrix((Y_data, indices))\n",
    "Y_data_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run PCA on Y_data_coo where 3462 cells and 63257 junctions \n",
    "# reduce dimensionality of junctions with PCA while keeping the cells \n",
    "# (i.e. we want to keep the cell clusters, but reduce the number of junctions)\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Assuming your sparse matrix is called 'sparse_matrix'\n",
    "dense_matrix = Y_data_coo.toarray()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)  # Set the desired number of components\n",
    "pca_result = pca.fit_transform(dense_matrix)\n",
    "\n",
    "# Access the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PCA on these mean 0 centers junction usage ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = cell_ids_conversion.cell_type\n",
    "pca = PCA(n_components=20)  # Set the number of components to 2 for visualization\n",
    "pca_result = pca.fit_transform(dense_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pcas(pca_result, cell_types, pc1, pc2):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.scatterplot(x=pca_result[:, pc1], y=pca_result[:, pc2], hue=cell_types, size=0.25)\n",
    "    plt.legend(fontsize='6', loc='upper left')\n",
    "    plt.xlabel('Principal Component:' + str(pc1))\n",
    "    plt.ylabel('Principal Component:' + str(pc2))\n",
    "    plt.title('PCA Scatter Plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_input=make_torch_data(final_data, **float_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make matrix of cell_ids as rows and junction_id_index as columns filled in by juncratio \n",
    "# this is the matrix we will use for PCA\n",
    "\n",
    "# final_data_pivot = final_data.pivot(index='cell_id_index', columns='junction_id_index', values='juncratio').fillna(0) <- if junction usage ratios are all positive, then how do we know we are not just picking up expression?\n",
    "# the zeroes im inputting here might just be cases where genes are just not expressed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data.head())\n",
    "print(len(final_data.cell_id_index.unique())) # number of cells\n",
    "print(len(final_data.junction_id_index.unique())) # number of junctions --> 125,611???? fixed now i think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#junction_data = final_data_pivot.iloc[:, 1:].values\n",
    "\n",
    "# Standardize the data (mean=0, variance=1)\n",
    "#scaler = StandardScaler()\n",
    "#normalized_data = scaler.fit_transform(junction_data)\n",
    "# Perform PCA\n",
    "\n",
    "#pca = PCA(n_components=10)  # Set the number of components to 2 for visualization\n",
    "#pca_result = pca.fit_transform(junction_data)\n",
    "\n",
    "# make a few plots side by side comparing different PC combinations\n",
    "# PC1 vs PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1 # can't currently run more than 1 or overflow GPU memory :( \n",
    "num_iters = 20 # should also be an argument that gets fed in\n",
    "K = 30\n",
    "\n",
    "# run coordinate ascent VI\n",
    "print(\"Number of topics to be learned is: \", K)\n",
    "ALPHA_f, PI_f, GAMMA_f, PHI_f, elbos_all = calculate_CAVI(K, LDA_input, float_type, hypers = hypers, num_iterations = num_iters)\n",
    "elbos_all = np.array(elbos_all)\n",
    "# plot ELBO\n",
    "plt.plot(elbos_all[2:]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juncs_probs = ALPHA_f / (ALPHA_f+PI_f)\n",
    "\n",
    "# how variable are juncs_probs across cell states/topics? \n",
    "plt.hist(juncs_probs.std(axis=1)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juncs_probs_df = pd.DataFrame(juncs_probs, columns = range(K))\n",
    "juncs_probs_df[\"junction_id_index\"] = junction_ids_conversion.junction_id_index.values\n",
    "# convert to juncs_probs to pandas dataframe and calculate mean and std across cell states/topics\n",
    "juncs_probs_df[\"junction_id\"] = junction_ids_conversion.junction_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_juncObsUsage(junc_index):\n",
    "\n",
    "    # print junction ID using junction_ids_conversion\n",
    "    print(junction_ids_conversion[junction_ids_conversion[\"junction_id_index\"] == junc_index])\n",
    "    junc_id = junction_ids_conversion[junction_ids_conversion[\"junction_id_index\"] == junc_index].junction_id.values[0]\n",
    "\n",
    "    # get data for just junc_index \n",
    "    junc_dat=final_data[final_data.junction_id_index==junc_index]\n",
    "\n",
    "    # make violin plot for junc_dat junction usage ratio coloured by cell_type and rotate plot 90 degrees\n",
    "    plot = ggplot(junc_dat, aes(x='cell_type', y='juncratio', fill=\"cell_type\")) + geom_violin() + geom_point() + plotnine.labels.ggtitle(junc_id) + plotnine.coords.coord_flip() \n",
    "    print(plot)\n",
    "\n",
    "def plot_juncProbs(junc_index):\n",
    "    \n",
    "    # print junction ID using junction_ids_conversion\n",
    "    print(junction_ids_conversion[junction_ids_conversion[\"junction_id_index\"] == junc_index])\n",
    "    junc_id = junction_ids_conversion[junction_ids_conversion[\"junction_id_index\"] == junc_index].junction_id.values[0]\n",
    "    \n",
    "    # get data for just junc_index \n",
    "    junc_dat=juncs_probs_df[juncs_probs_df.junction_id_index==junc_index]\n",
    "    junc_dat = junc_dat.melt().iloc[0:K]\n",
    "    junc_dat.value = junc_dat.value.astype(float)\n",
    "    # make violin plot for junc_dat junction usage ratio coloured by cell_type\n",
    "    plot = ggplot(junc_dat, aes(x='variable', y='value')) + geom_point() \n",
    "    print(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juncs_probs_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate plot should be small 4 by 4\n",
    "plotnine.options.figure_size = (4, 4)\n",
    "plot_juncObsUsage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_juncProbs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_f = GAMMA_f / GAMMA_f.sum(1,keepdim=True)\n",
    "theta_f_plot = pd.DataFrame(theta_f.cpu())\n",
    "theta_f_plot['cell_id'] = cell_ids_conversion[\"cell_type\"].to_numpy() # are these correct attachments? \n",
    "theta_f_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=theta_f_plot, y=\"cell_id\", x=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=theta_f_plot, y=\"cell_id\", x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use theta_f values to do PCA \n",
    "theta_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed theta_f into PCA\n",
    "pca = PCA(n_components=10)  # Set the number of components to 2 for visualization\n",
    "pca_result = pca.fit_transform(theta_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(pca_result, cell_types, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make heatmap using pca_result\n",
    "sns.heatmap(pca_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = {}\n",
    "unique_cell_types = set(cell_types)\n",
    "num_colors = len(unique_cell_types)\n",
    "color_palette = sns.color_palette('hsv', num_colors)  # Choose a color palette\n",
    "color_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cell_type in enumerate(unique_cell_types):\n",
    "    color_mapping[cell_type] = color_palette[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(theta_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leafcutter-sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
