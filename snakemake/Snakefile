import pandas as pd
from pathlib import Path
import subprocess
from os.path import join

configfile: "/gpfs/commons/home/kisaev/zoo-splice/parse-pbmc/leafcutter/config/config_samples.json"
configfile: "/gpfs/commons/home/kisaev/zoo-splice/parse-pbmc/leafcutter/config/cluster.yaml"

#PBMC data

### Globals ---------------------------------------------------------------------

# A Snakemake regular expression matching bam files.

input_table=config["sample_file"]
SAMPLES = pd.read_csv(input_table, header=None).loc[:, 0].tolist()
print(SAMPLES)

# Add wildcard constraint 

wildcard_constraints:
    sample="[^\/]+"

### Rules -----------------------------------------------------------------------

# Pipeline output files
# 

#rerun making junctions and remove "hg38" from chromosome names (add back that first rule)
#config["juncDir"] + "leafcutter_perind_numers.counts.gz"
#expand(join(config["juncDir"], "{sample}.junc"), sample=SAMPLES)

rule all:
	input:
		expand(join(config["juncDir"], "{sample}.junction"), sample=SAMPLES)

# Remove genome name from chromosome (add arguement so that it can be anything)

rule rm_specie_name:
	input:
		bams=join(config["bamDir"], "{sample}.bam"),
	params:
		spec="hg38", #spec param represents anything that user wants to remove from chromosome name that might be in bam file 
	output:
		bam_files=join(config["bamDir"], "{sample}.clean.bam"),
	wildcard_constraints:
		sample="[^\/]+"
	message:
		"Remove specie name from chromosome names"
	shell:
		r"samtools view -H {input.bams} | sed -e s/{params.spec}_//g | samtools reheader - {input.bams} > {output.bam_files}"

#make bam file index 

rule make_index: #why is this not showing up as a job
	input:
		bam=join(config["bamDir"], "{sample}.clean.bam"),
	message:
		"making index file for bam file"
	output:
		join(config["bamDir"], "{sample}.clean.bam.bai")
	shell:
		"""
		sambamba index {input.bam} 
		"""

#need to check if bam file already has an XS tag (this is important for strand information)
#latest version of star has to be installed (easiest from conda) 2.7.10b (also requires STAR genome index files which we can upload for Human...)
#realign bam files if no -xs tag present 

rule realign_bam: #need to make sure all files are done being created 
	input:
		bam=join(config["bamDir"], "{sample}.clean.bam"),
		bam_bai=join(config["bamDir"], "{sample}.clean.bam.bai"),
	params:
		genome_index="/gpfs/commons/groups/knowles_lab/Karin/star_genome",
		bam_files=join(config["bamDir"], "{sample}.clean.realigned_xs_"),
	message:
		"realigning BAM file in order to add -XS tag for junction strands"
	output:
		out_file=join(config["bamDir"], "{sample}.clean.realigned_xs_Log.final.out"), 
		out_bam=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.bam"), 
	shell:
		"""
		STAR --genomeDir {params.genome_index} --readFilesType SAM SE --readFilesCommand samtools view --readFilesIn {input.bam} --bamRemoveDuplicatesType UniqueIdentical --runMode alignReads --outSAMattributes XS --outSAMstrandField intronMotif --limitBAMsortRAM 44006670219 	--outSAMtype BAM SortedByCoordinate --runThreadN 4 --outFileNamePrefix {params.bam_files}
		"""

# reindex bam files -> it seems that for some files this rule isn't completed before get_junctions...
rule make_index_again:
	input:
		bam=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.bam"),
	message:
		"making index file for bam file"
	output:
		out_bai=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.bam.bai"),
	shell:
		"""
		sambamba index {input.bam}
		"""

rule deduplicate_umis:
	input:
		bam_use=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.bam"),
		bai_use=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.bam.bai"),
	message:
		"using umi_tools to deduplicate UMIs, don't want multiple reads coming from the same molecule for the same sequence"
	output:
		out_bam=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.dedup.bam"),
		out_bam_bai=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.dedup.bam.bai"),
		out_log=join(config["bamDir"], "{sample}.dedup.log"),
	shell:
		"""
		umi_tools dedup -I {input.bam_use} --extract-umi-method=tag --umi-tag=pN --spliced-is-unique --cell-tag=CB --method unique -S {output.out_bam} --log={output.out_log}
		#index file immdeiatley
		sambamba index {output.out_bam}
		"""

rule get_umi_counts:
	input:
		bam_use=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.bam"),
		bai_use=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.bam.bai"),
	message:
		"Count UMIs per gene per cell (only considers reads that are annotated with gene in the GX tag)"
	output:
		output_counts=join(config["bamDir"], "{sample}.counts.tsv.gz"),
	shell:
		"""
		umi_tools count --per-gene --gene-tag=GX --assigned-status-tag=XS --per-cell --cell-tag=CB -I {input.bam_use} -S {output.output_counts} --extract-umi-method=tag --umi-tag=pN
		"""

# Get junctions from pseudobulk files

rule get_junctions:
	input:
		bam_use=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.dedup.bam"),
		bai_use=join(config["bamDir"], "{sample}.clean.realigned_xs_Aligned.sortedByCoord.out.dedup.bam.bai"),
		umi_counts=join(config["bamDir"], "{sample}.counts.tsv.gz"),
	output:
		juncs=join(config["juncDir"], "{sample}.junction"),
		barcodes=join(config["juncDir"], "{sample}.barcodes"),
		juncswbarcodes=join(config["juncDir"], "{sample}.wbarcode.junc"),
	priority: 1
	wildcard_constraints:
		sample="[^\/]+"
	message:
		"Extracting junctions!"
	shell:
		"""
		regtools_run=/gpfs/commons/home/kisaev/regtools/build/regtools
		$regtools_run junctions extract -a 8 -m 50 -M 500000 {input.bam_use} -o {output.juncs} -s XS -b {output.barcodes}
		paste --delimiters='\t' {output.juncs} {output.barcodes} > {output.juncswbarcodes}
		"""

#to-do
#run beta-binomial LDA model on junction/cluster counts per cell 