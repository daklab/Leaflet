{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from load_cluster_data import load_cluster_data\n",
    "from pca_kmeans_init import pca_kmeans_init\n",
    "from betabinomo_LDA_singlecells_kinit import *\n",
    "import betabinomo_LDA_singlecells_kinit\n",
    "reload(betabinomo_LDA_singlecells_kinit)\n",
    "import torch\n",
    "import sklearn.manifold \n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/gpfs/commons/groups/knowles_lab/Karin/parse-pbmc-leafcutter/leafcutter/junctions/PBMC_input_for_LDA.h5'\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "MAKE_PCA_TSNE = True\n",
    "\n",
    "float_type = { \n",
    "    \"device\" : device, \n",
    "    \"dtype\" : torch.float, # save memory\n",
    "}\n",
    "\n",
    "hypers = {\n",
    "    \"eta\" : 1., \n",
    "    \"alpha_prior\" : 1., # karin had 0.65 \n",
    "    \"pi_prior\" : 1.\n",
    "}\n",
    "\n",
    "K = 15 # should also be an argument that gets fed in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data, coo_counts_sparse, coo_cluster_sparse, cell_ids_conversion, junction_ids_conversion = load_cluster_data(\n",
    "    input_file) # , celltypes = [\"B\", \"MemoryCD4T\"])\n",
    "N = coo_cluster_sparse.shape[0]\n",
    "J = coo_cluster_sparse.shape[1]\n",
    "\n",
    "my_data = make_torch_data(final_data, **float_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally plot reads per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_pcs, pc_sd, init_labels = pca_kmeans_init(final_data, my_data.junc_index, my_data.cell_index, K, float_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_scaled = cell_pcs.copy()\n",
    "pcs_scaled -= pcs_scaled.mean(1,keepdims=True)\n",
    "pcs_scaled /= pcs_scaled.std(1,keepdims=True)\n",
    "_ = plt.hist(pcs_scaled.flatten(),100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tSNE on scaled PCs (takes 5-10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_PCA_TSNE: \n",
    "    pcs_sd_scaled = cell_pcs * pc_sd\n",
    "\n",
    "    PCs_embedded = sklearn.manifold.TSNE(\n",
    "        n_components=2, \n",
    "        learning_rate='auto',\n",
    "        init='random', \n",
    "        perplexity=30).fit_transform(pcs_sd_scaled)\n",
    "\n",
    "    PC_embed_df = pd.DataFrame(PCs_embedded, columns = [\"x\",\"y\"])\n",
    "    PC_embed_df[\"cell_type\"] = cell_ids_conversion[\"cell_type\"].to_numpy()\n",
    "    #p9.ggplot(X_embed_df, p9.aes(x = \"x\", y=\"y\", color = \"cell_type\")) + p9.geom_point()\n",
    "\n",
    "    #plt.figure(figsize=[8,6]) # for pdf\n",
    "    plt.figure(figsize=[12,8])\n",
    "    sns.scatterplot(x = \"x\",y = \"y\", hue=\"cell_type\", data= PC_embed_df, edgecolor = 'none', alpha = 0.1)\n",
    "    plt.xlabel(\"tSNE 1\")\n",
    "    plt.ylabel(\"tSNE 2\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    #plt.savefig(\"pca_eig_scaled.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label by K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = [',', '.', 'o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X']\n",
    "    \n",
    "if MAKE_PCA_TSNE: \n",
    "    PC_embed_df[\"label\"] = init_labels\n",
    "\n",
    "    plt.figure(figsize=[12,8])\n",
    "    sns.scatterplot(\n",
    "        x = \"x\",y = \"y\", hue=\"label\", style=\"label\", data= PC_embed_df, \n",
    "        edgecolor = 'none', alpha = 0.1, markers = markers, palette=sns.color_palette(\"cubehelix\",15))\n",
    "    plt.xlabel(\"tSNE 1\")\n",
    "    plt.ylabel(\"tSNE 2\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1 # can't currently run more than 1 or overflow GPU memory :( \n",
    "num_iters = 300 # should also be an argument that gets fed in\n",
    "\n",
    "# loop over the number of trials (for now just testing using one trial but in general need to evaluate how performance is affected by number of trials)\n",
    "for t in range(num_trials):\n",
    "\n",
    "    # run coordinate ascent VI\n",
    "    print(K)\n",
    "\n",
    "    ALPHA_f, PI_f, GAMMA_f, PHI_f, elbos_all = calculate_CAVI(K, my_data, float_type, hypers = hypers, init_labels = init_labels, num_iterations = num_iters)\n",
    "    elbos_all = np.array(elbos_all)\n",
    "    juncs_probs = ALPHA_f / (ALPHA_f+PI_f)\n",
    "    #theta_f = distributions.Dirichlet(GAMMA_f).sample()\n",
    "    # z_f = distributions.Categorical(PHI_f).sample() # this would be pretty big! \n",
    "    #make theta_f a dataframe \n",
    "    theta_f = GAMMA_f / GAMMA_f.sum(1,keepdim=True)\n",
    "    theta_f_plot = pd.DataFrame(theta_f.cpu())\n",
    "    theta_f_plot['cell_id'] = cell_ids_conversion[\"cell_type\"].to_numpy()\n",
    "    theta_f_plot_summ = theta_f_plot.groupby('cell_id').mean()\n",
    "    print(theta_f_plot_summ)\n",
    "    \n",
    "    # save the learned variational parameters\n",
    "    #np.savez('variational_params.npz', ALPHA_f=ALPHA_f, PI_f=PI_f, GAMMA_f=GAMMA_f, PHI_f=PHI_f, juncs_probs=juncs_probs, theta_f=theta_f, z_f=z_f)\n",
    "\n",
    "\n",
    "    # plot ELBOs. With K=15 PCA-Kmeans init: -25159712.0\n",
    "    # With random initialization: -25259360.0 (so somewhat worse)\n",
    "    plt.plot(elbos_all[2:]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbos_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = theta_f.cpu().numpy()\n",
    "x -= x.mean(1,keepdims=True)\n",
    "x /= x.std(1,keepdims=True)\n",
    "plt.hist(x.flatten(),100)\n",
    "pd.crosstab( cell_ids_conversion[\"cell_type\"], x.argmax(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = sklearn.manifold.TSNE(\n",
    "    n_components=2, \n",
    "    learning_rate='auto',\n",
    "    init='random', \n",
    "    perplexity=100).fit_transform(x)\n",
    "X_embed_df = pd.DataFrame(X_embedded, columns = [\"x\",\"y\"])\n",
    "X_embed_df[\"cell_type\"] = cell_ids_conversion[\"cell_type\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,8])\n",
    "sns.scatterplot(x = \"x\",y = \"y\", hue=\"cell_type\", data= X_embed_df, edgecolor = 'none', alpha = 0.1)\n",
    "plt.xlabel(\"tSNE 1\")\n",
    "plt.ylabel(\"tSNE 2\")\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "#plt.savefig(\"pca_eig_scaled.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
