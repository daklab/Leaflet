{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The junctions are loaded from the following path: /gpfs/commons/home/kisaev/LeafletSC/data/raw/junctions/\n",
      "The files in the path are: ['B107926_O8_Blue_Blood_S250.homo.gencode.v30.ERCC.chrM.juncswbarcodes', 'B107925_B5_S284.homo.gencode.v30.ERCC.chrM.juncswbarcodes']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import polars as pl\n",
    "\n",
    "# Define path that contains some junction files (only 2 files are used for this example, corresponding to 2 individual cells)\n",
    "juncs_path = \"/gpfs/commons/home/kisaev/LeafletSC/data/raw/junctions/\"\n",
    "print(\"The junctions are loaded from the following path: \" + juncs_path) \n",
    "\n",
    "# print the files in the path \n",
    "print(\"The files in the path are: \" + str(os.listdir(juncs_path)))\n",
    "\n",
    "# define path for saving the output data \n",
    "output_path = \"/gpfs/commons/home/kisaev/LeafletSC/data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pyranges as pr\n",
    "from gtfparse import read_gtf #initially tested with version 1.3.0)\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import glob \n",
    "import time\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gtf(gtf_file): #make this into a seperate script that processes the gtf file into gr object that can be used in the main scriptas input \n",
    "    \"\"\"\n",
    "    Process the GTF file into a pyranges object.\n",
    "\n",
    "    Parameters:\n",
    "    - gtf_file (str): Path to the GTF file.\n",
    "\n",
    "    Returns:\n",
    "    - gtf_exons_gr (pyranges.GenomicRanges): Processed pyranges object.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"The gtf file you provided is \" + gtf_file)\n",
    "    print(\"This step may take a while depending on the size of your gtf file\")\n",
    "\n",
    "    # calculate how long it takes to read gtf_file and report it \n",
    "    start_time = time.time()\n",
    "    #[1] extract all exons from gtf file provided \n",
    "    gtf = read_gtf(gtf_file, result_type=\"pandas\") #to reduce the speed of this, can just get rows with exon in the feature column (preprocess this before running package)? check if really necessary\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Reading gtf file took \" + str(round((end_time-start_time), 2)) + \" seconds\")\n",
    "    # assert that gtf is a non empty dataframe otherwise return an error\n",
    "    if gtf.empty or type(gtf) != pd.DataFrame:\n",
    "        raise ValueError(\"The gtf file provided is empty or not a pandas DataFrame. Please provide a valid gtf file and ensure you have the \\\n",
    "                         latest version of gtfparse installed by running 'pip install gtfparse --upgrade'\")\n",
    "    \n",
    "    # Convert the seqname column to a string in gtf \n",
    "    gtf[\"seqname\"] = gtf[\"seqname\"].astype(str)\n",
    "\n",
    "    # Make a copy of the DataFrame\n",
    "    gtf_exons = gtf[(gtf[\"feature\"] == \"exon\")].copy()\n",
    "\n",
    "    if gtf_exons['seqname'].str.contains('chr').any():\n",
    "        gtf_exons.loc[gtf_exons['seqname'].str.contains('chr'), 'seqname'] = gtf_exons['seqname'].map(lambda x: x.lstrip('chr').rstrip('chr'))\n",
    "\n",
    "    if not set(['seqname', 'start', 'end', 'score', 'strand', 'gene_id', 'gene_name', 'transcript_id', 'exon_id']).issubset(gtf_exons.columns):\n",
    "        # print the columns that the file is missing\n",
    "        missing_cols = set(['seqname', 'start', 'end', 'score', 'strand', 'gene_id', 'gene_name', 'transcript_id', 'exon_id']).difference(gtf_exons.columns)\n",
    "        print(\"Your gtf file is missing the following columns: \" + str(missing_cols))\n",
    "\n",
    "        # if the missing column is just exon_id, we can generate it\n",
    "        if \"exon_id\" in missing_cols:\n",
    "            # add exon_id to gtf_exons\n",
    "            print(\"Adding exon_id column to gtf file\")\n",
    "            gtf_exons.loc[:, \"exon_id\"] = gtf_exons[\"transcript_id\"] + \"_\" + gtf_exons[\"start\"].astype(str) + \"_\" + gtf_exons[\"end\"].astype(str)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Convert the DataFrame to a PyRanges object\n",
    "    gtf_exons_gr = pr.from_dict({\"Chromosome\": gtf_exons[\"seqname\"], \"Start\": gtf_exons[\"start\"], \"End\": gtf_exons[\"end\"], \"Strand\": gtf_exons[\"strand\"], \"gene_id\": gtf_exons[\"gene_id\"], \"gene_name\": gtf_exons[\"gene_name\"], \"transcript_id\": gtf_exons[\"transcript_id\"], \"exon_id\": gtf_exons[\"exon_id\"]})\n",
    "\n",
    "    # Remove rows where exon start and end are the same or when gene_name is empty\n",
    "    gtf_exons_gr = gtf_exons_gr[ ~ (gtf_exons_gr.Start == gtf_exons_gr.End)]\n",
    "    gtf_exons_gr = gtf_exons_gr[ ~ (gtf_exons_gr.gene_name == \"\")]\n",
    "\n",
    "    # When do I need to do this? depends on gtf file used? base 0 or 1? probably need this to be a parameter \n",
    "    gtf_exons_gr.Start = gtf_exons_gr.Start-1\n",
    "\n",
    "    # Drop duplicated positions on same strand \n",
    "    gtf_exons_gr = gtf_exons_gr.drop_duplicate_positions(strand=True) # Why are so many gone after this? \n",
    "\n",
    "    # Print the number of unique exons, transcript ids, and gene ids\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"The number of unique exons is \" + str(len(gtf_exons_gr.exon_id.unique())))\n",
    "    print(\"The number of unique transcript ids is \" + str(len(gtf_exons_gr.transcript_id.unique())))\n",
    "    print(\"The number of unique gene ids is \" + str(len(gtf_exons_gr.gene_id.unique())))\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    return(gtf_exons_gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_clusters(clust_info):\n",
    "    # for all start positions that are same for each cluster get the sum counts_total\n",
    "    clust_info_5ss = clust_info.groupby(['Cluster', 'Start']).agg({'counts_total': 'sum'}).reset_index()\n",
    "    clust_info_3_ss = clust_info.groupby(['Cluster', 'End']).agg({'counts_total': 'sum'}).reset_index()\n",
    "    # rename columns in 5ss to be total 5ss counts\n",
    "    clust_info_5ss.rename(columns={'counts_total': 'total_5ss_counts'}, inplace=True)\n",
    "    clust_info_3_ss.rename(columns={'counts_total': 'total_3ss_counts'}, inplace=True)\n",
    "    # remove Start and End column from each\n",
    "    clust_info = clust_info.merge(clust_info_5ss, on=['Cluster', 'Start'])\n",
    "    clust_info = clust_info.merge(clust_info_3_ss, on=['Cluster', 'End'])\n",
    "\n",
    "    # give each junction a 5ss fraction and 3ss fraction and then add column counts_total \n",
    "    clust_info['5SS_usage'] = clust_info['counts_total'] / clust_info['total_5ss_counts']\n",
    "    clust_info['3SS_usage'] = clust_info['counts_total'] / clust_info['total_3ss_counts']\n",
    "    clust_info[\"min_usage\"] = clust_info[[\"5SS_usage\", \"3SS_usage\"]].min(axis=1)\n",
    "    print(\"Done refining clusters!\")\n",
    "    return(clust_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_junctions_by_shared_splice_sites(df):\n",
    "    # Function to apply to each group (cluster)\n",
    "    def filter_group(group):\n",
    "        # Find duplicated start and end positions within the group\n",
    "        duplicated_starts = group['Start'].duplicated(keep=False)\n",
    "        duplicated_ends = group['End'].duplicated(keep=False)\n",
    "        \n",
    "        # Keep rows where either start or end position is duplicated\n",
    "        return group[duplicated_starts | duplicated_ends]\n",
    "    \n",
    "    # Group by 'Cluster' and apply the filtering function\n",
    "    filtered_df = df.groupby('Cluster').apply(filter_group).reset_index(drop=True)\n",
    "    return filtered_df.Cluster.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_junction_files(junc_files, junc_suffix):\n",
    "    \"\"\"\n",
    "    Read junction files.\n",
    "\n",
    "    Parameters:\n",
    "    - junc_files (list): List of paths to junction files.\n",
    "    - junc_suffix (str): Suffix of junction files.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated DataFrame of junction files.\n",
    "    \"\"\"\n",
    "    all_juncs_list = []\n",
    "\n",
    "    for junc_path in junc_files:\n",
    "        junc_path = Path(junc_path)\n",
    "        print(f\"Reading in junction files from {junc_path}\")\n",
    "\n",
    "        junc_files_in_path = list(junc_path.rglob(junc_suffix))\n",
    "        if not junc_files_in_path:\n",
    "            print(f\"No junction files found in {junc_path} with suffix {junc_suffix}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"The number of junction files to be processed is {len(junc_files_in_path)}\")\n",
    "\n",
    "        files_not_read = []\n",
    "\n",
    "        for junc_file in tqdm(junc_files_in_path):\n",
    "            try:\n",
    "                juncs = pd.read_csv(junc_file, sep=\"\\t\", header=None)\n",
    "                juncs['file_name'] = junc_file  # Add the file name as a new column\n",
    "                juncs['cell_type'] = junc_file\n",
    "                all_juncs_list.append(juncs)  # Append the DataFrame to the list\n",
    "            except Exception as e:\n",
    "                print(f\"Could not read in {junc_file}: {e}\")\n",
    "                files_not_read.append(junc_file)\n",
    "\n",
    "    if len(files_not_read) > 0:\n",
    "        print(\"The total number of files that could not be read is \" + str(len(files_not_read)) + \" as these had no junctions\")\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    all_juncs = pd.concat(all_juncs_list, ignore_index=True) if all_juncs_list else pd.DataFrame()\n",
    "\n",
    "    return all_juncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_juncs(all_juncs, col_names, min_intron, max_intron):\n",
    "    \n",
    "    # Apply column names to the DataFrame\n",
    "    all_juncs.columns = col_names\n",
    "    \n",
    "    # Split 'blockSizes' into two new columns and convert them to integers (this step takes a while)\n",
    "    all_juncs[['block_add_start', 'block_subtract_end']] = all_juncs[\"blockSizes\"].str.split(',', expand=True).astype(int)\n",
    "\n",
    "    # Adjust 'chromStart' and 'chromEnd' based on 'block_add_start' and 'block_subtract_end'\n",
    "    all_juncs[\"chromStart\"] += all_juncs['block_add_start']\n",
    "    all_juncs[\"chromEnd\"] -= all_juncs['block_subtract_end']\n",
    "\n",
    "    # Calculate 'intron_length' and filter based on 'min_intron' and 'max_intron'\n",
    "    all_juncs[\"intron_length\"] = all_juncs[\"chromEnd\"] - all_juncs[\"chromStart\"]\n",
    "    mask = (all_juncs[\"intron_length\"] >= min_intron) & (all_juncs[\"intron_length\"] <= max_intron)\n",
    "    all_juncs = all_juncs[mask]\n",
    "\n",
    "    # Filter for 'chrom' column to handle \"chr\" prefix\n",
    "    all_juncs = all_juncs.copy()\n",
    "\n",
    "    # New filter for 'chrom' column to handle \"chr\" prefix, using .loc for safe in-place modification\n",
    "    standard_chromosomes_pattern = r'^(?:chr)?(?:[1-9]|1[0-9]|2[0-2]|X|Y|MT)$'\n",
    "    all_juncs = all_juncs[all_juncs['chrom'].str.match(standard_chromosomes_pattern)]\n",
    "\n",
    "    print(\"Cleaning up 'chrom' column\")\n",
    "    # Remove \"chr\" prefix from 'chrom' column\n",
    "    all_juncs['chrom'] = all_juncs['chrom'].str.replace(r'^chr', '', regex=True)\n",
    "    \n",
    "    # Add 'junction_id' column\n",
    "    all_juncs['junction_id'] = all_juncs['chrom'] + '_' + all_juncs['chromStart'].astype(str) + '_' + all_juncs['chromEnd'].astype(str)\n",
    "    \n",
    "    # Get total score for each junction and merge with all_juncs with new column \"total_counts\"\n",
    "    all_juncs = all_juncs.groupby('junction_id').agg({'score': 'sum'}).reset_index().merge(all_juncs, on='junction_id', how='left')\n",
    "\n",
    "    # rename score_x and score_y to total_junc_counts and score \n",
    "    all_juncs.rename(columns={'score_x': 'counts_total', 'score_y': 'score'}, inplace=True)\n",
    "\n",
    "    return(all_juncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_juncs_exons(juncs_gr, gtf_exons_gr, singletons):\n",
    "    print(\"Annotating junctions with known exons based on input gtf file\")\n",
    "    \n",
    "    # for each junction, the start of the junction should equal end of exons and end of junction should equal start of exon \n",
    "    juncs_gr = juncs_gr.k_nearest(gtf_exons_gr, strandedness = \"same\", ties=\"different\", k=2, overlap=False)\n",
    "    # ensure distance parameter is still 1 \n",
    "    juncs_gr = juncs_gr[abs(juncs_gr.Distance) == 1]\n",
    "\n",
    "    # group juncs_gr by gene_id and ensure that each junction has Start and End aligning with at least one End_b and Start_b respectively\n",
    "    grouped_gr = juncs_gr.df.groupby(\"gene_id\")\n",
    "    juncs_keep = []\n",
    "    for name, group in grouped_gr:\n",
    "        group = group[(group.Start.isin(group.End_b)) & (group.End.isin(group.Start_b))]\n",
    "        # save junctions that are found here after filtering for matching start and end positions\n",
    "        juncs_keep.append(group.junction_id.unique())\n",
    "\n",
    "    # flatten the list of lists\n",
    "    juncs_keep = [item for sublist in juncs_keep for item in sublist]\n",
    "    juncs_gr = juncs_gr[juncs_gr.junction_id.isin(juncs_keep)]\n",
    "    \n",
    "    print(\"The number of junctions after assessing distance to exons is \" + str(len(juncs_gr.junction_id.unique())))\n",
    "    if len(juncs_gr.junction_id.unique()) < 5000:\n",
    "        print(\"There are less than 5000 junctions after assessing distance to exons. Please check your gtf file and ensure that it is in the correct format (start and end positions are not off by 1).\", flush=True)\n",
    "    \n",
    "    print(\"Clustering intron splicing events by gene_id\")\n",
    "    juncs_coords_unique = juncs_gr[['Chromosome', 'Start', 'End', 'Strand', 'junction_id', 'gene_id']].drop_duplicate_positions()\n",
    "    clusters = juncs_coords_unique.cluster(by=\"gene_id\", slack=-1, count=True)\n",
    "    print(\"The number of clusters after removing singletons is \" + str(len(clusters.Cluster.unique())))\n",
    "\n",
    "    if singletons == False:\n",
    "        # remove singletons \n",
    "        clusters = clusters[clusters.Count > 1]\n",
    "        print(\"The number of clusters after removing singletons is \" + str(len(clusters.Cluster.unique())))\n",
    "        # update juncs_gr to only include junctions that are part of clusters\n",
    "        juncs_gr = juncs_gr[juncs_gr.junction_id.isin(clusters.junction_id)]\n",
    "        # update juncs_coords_unique to only include junctions that are part of clusters\n",
    "        juncs_coords_unique = juncs_coords_unique[juncs_coords_unique.junction_id.isin(clusters.junction_id)]\n",
    "        print(\"The number of junctions after removing singletons is \" + str(len(juncs_coords_unique.junction_id.unique())))\n",
    "        return juncs_gr, juncs_coords_unique, clusters\n",
    "    else:\n",
    "        return juncs_gr, juncs_coords_unique, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# junc_files defines a path for where junction files can be found, in this case, the path is defined above\n",
    "junc_files = juncs_path\n",
    "\n",
    "# we provide a gtf file for the human genome as well to make better sense of the junctions that are detected in cells\n",
    "# please replace with the path to the gtf file on your system\n",
    "gtf_file=\"/gpfs/commons/groups/knowles_lab/Karin/genome_files/gencode.v43.basic.annotation.gtf\" \n",
    "\n",
    "# define additional parameters \n",
    "sequencing_type = \"single_cell\"\n",
    "\n",
    "# ensure output files are to be saved in output_path \n",
    "output_file = output_path + \"test_intron_clusters\"\n",
    "junc_bed_file= output_path + \"test_juncs.bed\" # you can load this file into IGV to visualize the junction coordinates \n",
    "min_intron_length = 50\n",
    "max_intron_length = 500000\n",
    "threshold_inc = 0.05 \n",
    "min_junc_reads = 2\n",
    "min_num_cells_wjunc = 2\n",
    "keep_singletons = False # ignore junctions that do not share splice sites with any other junction (likely const)\n",
    "junc_suffix = \"*.juncswbarcodes\" \n",
    "\n",
    "if \",\" in junc_files:\n",
    "    junc_files = junc_files.split(\",\")\n",
    "else:\n",
    "    junc_files = [junc_files]\n",
    "all_juncs_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpfs/commons/home/kisaev/LeafletSC/data/raw/junctions/']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gtf file you provided is /gpfs/commons/groups/knowles_lab/Karin/genome_files/gencode.v43.basic.annotation.gtf\n",
      "This step may take a while depending on the size of your gtf file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'tag', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'havana_transcript', 'exon_number', 'exon_id', 'hgnc_id', 'havana_gene', 'ont', 'protein_id', 'ccdsid', 'artif_dupl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gtf file took 115.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/kisaev/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  return {k: v for k, v in df.groupby(grpby_key)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "The number of unique exons is 411865\n",
      "The number of unique transcript ids is 115526\n",
      "The number of unique gene ids is 62668\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Done extracting exons from gtf file\n"
     ]
    }
   ],
   "source": [
    "if gtf_file is not None:\n",
    "    gtf_exons_gr = process_gtf(gtf_file)\n",
    "    print(\"Done extracting exons from gtf file\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in junction files from /gpfs/commons/home/kisaev/LeafletSC/data/raw/junctions\n",
      "The number of junction files to be processed is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 15.99it/s]\n"
     ]
    }
   ],
   "source": [
    "all_juncs = read_junction_files(junc_files, junc_suffix)\n",
    "# Define column names based on sequencing type\n",
    "col_names = [\"chrom\", \"chromStart\", \"chromEnd\", \"name\", \"score\", \"strand\", \n",
    "         \"thickStart\", \"thickEnd\", \"itemRgb\", \"blockCount\", \"blockSizes\", \"blockStarts\"]\n",
    "if sequencing_type == \"single_cell\":\n",
    "    col_names += [\"num_cells_wjunc\", \"cell_readcounts\"]\n",
    "col_names += [\"file_name\", \"cell_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up 'chrom' column\n",
      "Number of unique junctions is 14416\n"
     ]
    }
   ],
   "source": [
    "all_juncs = clean_up_juncs(all_juncs, col_names, min_intron_length, max_intron_length)\n",
    "print(\"Number of unique junctions is \" + str(len(all_juncs.junction_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/kisaev/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  return {k: v for k, v in df.groupby(grpby_key)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making gr object from all junctions across all cell types\n"
     ]
    }
   ],
   "source": [
    "# 7. Make gr object from ALL junctions across all cell types \n",
    "print(\"Making gr object from all junctions across all cell types\")\n",
    "juncs_gr = pr.from_dict({\"Chromosome\": all_juncs[\"chrom\"], \"Start\": all_juncs[\"chromStart\"], \"End\": all_juncs[\"chromEnd\"], \"Strand\": all_juncs[\"strand\"], \"Cell\": all_juncs[\"cell_type\"], \"junction_id\": all_juncs[\"junction_id\"], \"counts_total\": all_juncs[\"counts_total\"]})\n",
    "juncs_gr = juncs_gr[[\"Chromosome\", \"Start\", \"End\", \"Strand\", \"junction_id\", \"counts_total\"]].drop_duplicate_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if min_junc_reads is not none then remove junctions with less than min_junc_reads\n",
    "if min_junc_reads is not None:\n",
    "    juncs_gr = juncs_gr[juncs_gr.counts_total > min_junc_reads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating junctions with known exons based on input gtf file\n",
      "The number of junctions after assessing distance to exons is 11689\n",
      "Clustering intron splicing events by gene_id\n",
      "The number of clusters after removing singletons is 11189\n",
      "The number of clusters after removing singletons is 223\n",
      "The number of junctions after removing singletons is 723\n"
     ]
    }
   ],
   "source": [
    "if gtf_file is not None:\n",
    "    juncs_gr, juncs_coords_unique, clusters = mapping_juncs_exons(juncs_gr, gtf_exons_gr, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>junction_id</th>\n",
       "      <th>counts_total</th>\n",
       "      <th>Start_b</th>\n",
       "      <th>End_b</th>\n",
       "      <th>Strand_b</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>exon_id</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101237099</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101237099_101238821</td>\n",
       "      <td>128</td>\n",
       "      <td>101237018</td>\n",
       "      <td>101237099</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "      <td>S1PR1</td>\n",
       "      <td>ENST00000305352.7</td>\n",
       "      <td>ENSE00001356737.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101237099</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101237099_101238821</td>\n",
       "      <td>128</td>\n",
       "      <td>101238821</td>\n",
       "      <td>101241518</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "      <td>S1PR1</td>\n",
       "      <td>ENST00000305352.7</td>\n",
       "      <td>ENSE00001167649.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>101237099</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101237099_101238821</td>\n",
       "      <td>128</td>\n",
       "      <td>101238821</td>\n",
       "      <td>101241189</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "      <td>S1PR1</td>\n",
       "      <td>ENST00000649383.1</td>\n",
       "      <td>ENSE00003834657.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>101237099</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101237099_101238821</td>\n",
       "      <td>128</td>\n",
       "      <td>101238821</td>\n",
       "      <td>101241372</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "      <td>S1PR1</td>\n",
       "      <td>ENST00000475289.2</td>\n",
       "      <td>ENSE00001918985.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101237099</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101237099_101238821</td>\n",
       "      <td>128</td>\n",
       "      <td>101238821</td>\n",
       "      <td>101241308</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "      <td>S1PR1</td>\n",
       "      <td>ENST00000648480.1</td>\n",
       "      <td>ENSE00003835205.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>X</td>\n",
       "      <td>119616742</td>\n",
       "      <td>119625334</td>\n",
       "      <td>-</td>\n",
       "      <td>X_119616742_119625334</td>\n",
       "      <td>172</td>\n",
       "      <td>119625334</td>\n",
       "      <td>119625379</td>\n",
       "      <td>-</td>\n",
       "      <td>ENSG00000125354.24</td>\n",
       "      <td>SEPTIN6</td>\n",
       "      <td>ENST00000360156.11</td>\n",
       "      <td>ENSE00003594905.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>X</td>\n",
       "      <td>119620051</td>\n",
       "      <td>119629317</td>\n",
       "      <td>-</td>\n",
       "      <td>X_119620051_119629317</td>\n",
       "      <td>6</td>\n",
       "      <td>119616944</td>\n",
       "      <td>119620051</td>\n",
       "      <td>-</td>\n",
       "      <td>ENSG00000125354.24</td>\n",
       "      <td>SEPTIN6</td>\n",
       "      <td>ENST00000394610.7</td>\n",
       "      <td>ENSE00001455353.4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>X</td>\n",
       "      <td>119620051</td>\n",
       "      <td>119629317</td>\n",
       "      <td>-</td>\n",
       "      <td>X_119620051_119629317</td>\n",
       "      <td>6</td>\n",
       "      <td>119629317</td>\n",
       "      <td>119629508</td>\n",
       "      <td>-</td>\n",
       "      <td>ENSG00000125354.24</td>\n",
       "      <td>SEPTIN6</td>\n",
       "      <td>ENST00000360156.11</td>\n",
       "      <td>ENSE00003693275.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>X</td>\n",
       "      <td>119625379</td>\n",
       "      <td>119629317</td>\n",
       "      <td>-</td>\n",
       "      <td>X_119625379_119629317</td>\n",
       "      <td>167</td>\n",
       "      <td>119625334</td>\n",
       "      <td>119625379</td>\n",
       "      <td>-</td>\n",
       "      <td>ENSG00000125354.24</td>\n",
       "      <td>SEPTIN6</td>\n",
       "      <td>ENST00000360156.11</td>\n",
       "      <td>ENSE00003594905.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>X</td>\n",
       "      <td>119625379</td>\n",
       "      <td>119629317</td>\n",
       "      <td>-</td>\n",
       "      <td>X_119625379_119629317</td>\n",
       "      <td>167</td>\n",
       "      <td>119629317</td>\n",
       "      <td>119629508</td>\n",
       "      <td>-</td>\n",
       "      <td>ENSG00000125354.24</td>\n",
       "      <td>SEPTIN6</td>\n",
       "      <td>ENST00000360156.11</td>\n",
       "      <td>ENSE00003693275.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1904 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "+--------------+-----------+-----------+--------------+-------+\n",
       "| Chromosome   | Start     | End       | Strand       | +10   |\n",
       "| (category)   | (int64)   | (int64)   | (category)   | ...   |\n",
       "|--------------+-----------+-----------+--------------+-------|\n",
       "| 1            | 101237099 | 101238821 | +            | ...   |\n",
       "| 1            | 101237099 | 101238821 | +            | ...   |\n",
       "| 1            | 101237099 | 101238821 | +            | ...   |\n",
       "| 1            | 101237099 | 101238821 | +            | ...   |\n",
       "| ...          | ...       | ...       | ...          | ...   |\n",
       "| X            | 119620051 | 119629317 | -            | ...   |\n",
       "| X            | 119620051 | 119629317 | -            | ...   |\n",
       "| X            | 119625379 | 119629317 | -            | ...   |\n",
       "| X            | 119625379 | 119629317 | -            | ...   |\n",
       "+--------------+-----------+-----------+--------------+-------+\n",
       "Stranded PyRanges object has 1,904 rows and 14 columns from 23 chromosomes.\n",
       "For printing, the PyRanges was sorted on Chromosome and Strand.\n",
       "10 hidden columns: junction_id, counts_total, Start_b, End_b, Strand_b, ... (+ 5 more.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juncs_gr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_20999/3098945214.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_df = df.groupby('Cluster').apply(filter_group).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of clusters after filtering for shared splice sites is 214\n",
      "The number of junctions after filtering for shared splice sites is 703\n"
     ]
    }
   ],
   "source": [
    "# now for each cluster we want to check that each junction shares a splice site with at least one other junction in the cluster\n",
    "clusts_keep = filter_junctions_by_shared_splice_sites(clusters.df)\n",
    "# update clusters, juncs_gr, and juncs_coords_unique to only include clusters\n",
    "clusters = clusters[clusters.Cluster.isin(clusts_keep)]\n",
    "juncs_gr = juncs_gr[juncs_gr.junction_id.isin(clusters.junction_id)]\n",
    "juncs_coords_unique = juncs_coords_unique[juncs_coords_unique.junction_id.isin(clusters.junction_id)]\n",
    "print(\"The number of clusters after filtering for shared splice sites is \" + str(len(clusters.Cluster.unique())))\n",
    "print(\"The number of junctions after filtering for shared splice sites is \" + str(len(juncs_coords_unique.junction_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique junctions in juncs_gr is 703\n",
      "The number of unique junctions in all_juncs is 703\n",
      "The number of clusters in clusters is 214\n",
      "The number of unique junctions in clusters is 703\n"
     ]
    }
   ],
   "source": [
    "# update our all_juncs file to only include junctions that are part of clusters\n",
    "all_juncs = all_juncs[all_juncs.junction_id.isin(juncs_coords_unique.junction_id)]\n",
    "# double check that juncs_gr and all_juncs have the same number of unique junctions\n",
    "print(\"The number of unique junctions in juncs_gr is \" + str(len(juncs_gr.junction_id.unique())))\n",
    "print(\"The number of unique junctions in all_juncs is \" + str(len(all_juncs.junction_id.unique())))\n",
    "# also check clusters \n",
    "print(\"The number of clusters in clusters is \" + str(len(clusters.Cluster.unique())))\n",
    "print(\"The number of unique junctions in clusters is \" + str(len(clusters.junction_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining intron clusters to account for junction usage ratio threshold...\n",
      "Done refining clusters!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>junction_id</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>counts_total</th>\n",
       "      <th>total_5ss_counts</th>\n",
       "      <th>total_3ss_counts</th>\n",
       "      <th>5SS_usage</th>\n",
       "      <th>3SS_usage</th>\n",
       "      <th>min_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>1_175004814_175006744</td>\n",
       "      <td>175004814</td>\n",
       "      <td>175006744</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>0.052288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>1_175004833_175006744</td>\n",
       "      <td>175004833</td>\n",
       "      <td>175006744</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947712</td>\n",
       "      <td>0.947712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>1_145608175_145616233</td>\n",
       "      <td>145608175</td>\n",
       "      <td>145616233</td>\n",
       "      <td>218</td>\n",
       "      <td>238</td>\n",
       "      <td>218</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>1_145608175_145618319</td>\n",
       "      <td>145608175</td>\n",
       "      <td>145618319</td>\n",
       "      <td>20</td>\n",
       "      <td>238</td>\n",
       "      <td>158</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.084034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>1_145616293_145618319</td>\n",
       "      <td>145616293</td>\n",
       "      <td>145618319</td>\n",
       "      <td>138</td>\n",
       "      <td>138</td>\n",
       "      <td>158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.873418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster            junction_id      Start        End  counts_total  \\\n",
       "0       69  1_175004814_175006744  175004814  175006744             8   \n",
       "1       69  1_175004833_175006744  175004833  175006744           145   \n",
       "2      150  1_145608175_145616233  145608175  145616233           218   \n",
       "3      150  1_145608175_145618319  145608175  145618319            20   \n",
       "4      150  1_145616293_145618319  145616293  145618319           138   \n",
       "\n",
       "   total_5ss_counts  total_3ss_counts  5SS_usage  3SS_usage  min_usage  \n",
       "0                 8               153   1.000000   0.052288   0.052288  \n",
       "1               145               153   1.000000   0.947712   0.947712  \n",
       "2               238               218   0.915966   1.000000   0.915966  \n",
       "3               238               158   0.084034   0.126582   0.084034  \n",
       "4               138               158   1.000000   0.873418   0.873418  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Refining intron clusters to account for junction usage ratio threshold...\")\n",
    "juncs_counts = juncs_gr.df[['junction_id', 'Start', 'End', 'counts_total']].drop_duplicates()\n",
    "clust_info = clusters.df[['Cluster', 'junction_id']].drop_duplicates()\n",
    "clust_info = clust_info.merge(juncs_counts)\n",
    "junc_scores_all = refine_clusters(clust_info)\n",
    "junc_scores_all = junc_scores_all[junc_scores_all.min_usage >= threshold_inc]\n",
    "# add 5ss and 3ss usatio of each junction to all_juncs\n",
    "junc_scores_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>junction_id</th>\n",
       "      <th>counts_total</th>\n",
       "      <th>chrom</th>\n",
       "      <th>chromStart</th>\n",
       "      <th>chromEnd</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>thickStart</th>\n",
       "      <th>thickEnd</th>\n",
       "      <th>...</th>\n",
       "      <th>cell_readcounts</th>\n",
       "      <th>file_name</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>block_add_start</th>\n",
       "      <th>block_subtract_end</th>\n",
       "      <th>intron_length</th>\n",
       "      <th>total_5ss_counts</th>\n",
       "      <th>total_3ss_counts</th>\n",
       "      <th>5SS_usage</th>\n",
       "      <th>3SS_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_118326243_118335113</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>118326243</td>\n",
       "      <td>118335113</td>\n",
       "      <td>JUNC00005275</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>118326153</td>\n",
       "      <td>118335119</td>\n",
       "      <td>...</td>\n",
       "      <td>B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>8870</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_118326243_118335553</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>118326243</td>\n",
       "      <td>118335553</td>\n",
       "      <td>JUNC00005276</td>\n",
       "      <td>16</td>\n",
       "      <td>-</td>\n",
       "      <td>118326164</td>\n",
       "      <td>118335637</td>\n",
       "      <td>...</td>\n",
       "      <td>B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>9310</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_12210322_12215739</td>\n",
       "      <td>111</td>\n",
       "      <td>10</td>\n",
       "      <td>12210322</td>\n",
       "      <td>12215739</td>\n",
       "      <td>JUNC00004927</td>\n",
       "      <td>111</td>\n",
       "      <td>+</td>\n",
       "      <td>12210289</td>\n",
       "      <td>12215835</td>\n",
       "      <td>...</td>\n",
       "      <td>B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "      <td>5417</td>\n",
       "      <td>114</td>\n",
       "      <td>111</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_12215835_12217360</td>\n",
       "      <td>117</td>\n",
       "      <td>10</td>\n",
       "      <td>12215835</td>\n",
       "      <td>12217360</td>\n",
       "      <td>JUNC00004929</td>\n",
       "      <td>117</td>\n",
       "      <td>+</td>\n",
       "      <td>12215739</td>\n",
       "      <td>12217459</td>\n",
       "      <td>...</td>\n",
       "      <td>B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>96</td>\n",
       "      <td>99</td>\n",
       "      <td>1525</td>\n",
       "      <td>117</td>\n",
       "      <td>120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_3779590_3780105</td>\n",
       "      <td>341</td>\n",
       "      <td>10</td>\n",
       "      <td>3779590</td>\n",
       "      <td>3780105</td>\n",
       "      <td>JUNC00004884</td>\n",
       "      <td>104</td>\n",
       "      <td>-</td>\n",
       "      <td>3779495</td>\n",
       "      <td>3780203</td>\n",
       "      <td>...</td>\n",
       "      <td>B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>/gpfs/commons/home/kisaev/LeafletSC/data/raw/j...</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>515</td>\n",
       "      <td>347</td>\n",
       "      <td>341</td>\n",
       "      <td>0.982709</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              junction_id  counts_total chrom  chromStart   chromEnd  \\\n",
       "0  10_118326243_118335113             6    10   118326243  118335113   \n",
       "1  10_118326243_118335553            16    10   118326243  118335553   \n",
       "2    10_12210322_12215739           111    10    12210322   12215739   \n",
       "3    10_12215835_12217360           117    10    12215835   12217360   \n",
       "4      10_3779590_3780105           341    10     3779590    3780105   \n",
       "\n",
       "           name  score strand  thickStart   thickEnd  ...  \\\n",
       "0  JUNC00005275      6      -   118326153  118335119  ...   \n",
       "1  JUNC00005276     16      -   118326164  118335637  ...   \n",
       "2  JUNC00004927    111      +    12210289   12215835  ...   \n",
       "3  JUNC00004929    117      +    12215739   12217459  ...   \n",
       "4  JUNC00004884    104      -     3779495    3780203  ...   \n",
       "\n",
       "                                     cell_readcounts  \\\n",
       "0  B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...   \n",
       "1  B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...   \n",
       "2  B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...   \n",
       "3  B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...   \n",
       "4  B107926_O8_Blue_Blood_S250.homo.gencode.v30.ER...   \n",
       "\n",
       "                                           file_name  \\\n",
       "0  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...   \n",
       "1  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...   \n",
       "2  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...   \n",
       "3  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...   \n",
       "4  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...   \n",
       "\n",
       "                                           cell_type block_add_start  \\\n",
       "0  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...              90   \n",
       "1  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...              79   \n",
       "2  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...              33   \n",
       "3  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...              96   \n",
       "4  /gpfs/commons/home/kisaev/LeafletSC/data/raw/j...              95   \n",
       "\n",
       "   block_subtract_end intron_length total_5ss_counts total_3ss_counts  \\\n",
       "0                   6          8870               22                6   \n",
       "1                  84          9310               22               16   \n",
       "2                  96          5417              114              111   \n",
       "3                  99          1525              117              120   \n",
       "4                  98           515              347              341   \n",
       "\n",
       "   5SS_usage  3SS_usage  \n",
       "0   0.272727      1.000  \n",
       "1   0.727273      1.000  \n",
       "2   0.973684      1.000  \n",
       "3   1.000000      0.975  \n",
       "4   0.982709      1.000  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_juncs = all_juncs.merge(junc_scores_all[['junction_id', 'total_5ss_counts', 'total_3ss_counts', \"5SS_usage\", \"3SS_usage\"]], on='junction_id')\n",
    "all_juncs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of clusters after removing low confidence junctions is 214\n"
     ]
    }
   ],
   "source": [
    "# remove junctions that are in junc_scores_all from juncs_gr, clusters, all_juncs and juncs_coords_unique\n",
    "juncs_gr = juncs_gr[juncs_gr.junction_id.isin(junc_scores_all.junction_id)]\n",
    "clusters = clusters[clusters.junction_id.isin(junc_scores_all.junction_id)]\n",
    "all_juncs = all_juncs[all_juncs.junction_id.isin(junc_scores_all.junction_id)]\n",
    "juncs_coords_unique = juncs_coords_unique[juncs_coords_unique.junction_id.isin(junc_scores_all.junction_id)]\n",
    "print(\"The number of clusters after removing low confidence junctions is \" + str(len(clusters.Cluster.unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique junctions in juncs_gr is 577\n",
      "The number of unique junctions in all_juncs is 577\n",
      "The number of clusters in clusters is 214\n",
      "The number of unique junctions in clusters is 577\n"
     ]
    }
   ],
   "source": [
    "# double check that juncs_gr and all_juncs have the same number of unique junctions\n",
    "print(\"The number of unique junctions in juncs_gr is \" + str(len(juncs_gr.junction_id.unique())))\n",
    "print(\"The number of unique junctions in all_juncs is \" + str(len(all_juncs.junction_id.unique())))\n",
    "# also check clusters \n",
    "print(\"The number of clusters in clusters is \" + str(len(clusters.Cluster.unique())))\n",
    "print(\"The number of unique junctions in clusters is \" + str(len(clusters.junction_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclustering intron splicing events after low confidence junction removal\n"
     ]
    }
   ],
   "source": [
    "# 12. given junctions that remain, see if need to recluster introns (low confidence junctions removed)\n",
    "print(\"Reclustering intron splicing events after low confidence junction removal\")\n",
    "# check if there are any duplicate entried in pyranges object \n",
    "juncs_gr = juncs_gr.drop_duplicate_positions()\n",
    "# drop original cluster column and add new one\n",
    "clusters = juncs_gr.cluster(by=\"gene_id\", slack=-1, count=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusters[clusters.Count > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/kisaev/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pyranges/tostring2.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([plus, minus])\n",
      "/gpfs/commons/home/kisaev/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pyranges/tostring2.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([plus, minus])\n",
      "/gpfs/commons/home/kisaev/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pyranges/tostring2.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([plus, minus])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>junction_id</th>\n",
       "      <th>counts_total</th>\n",
       "      <th>Start_b</th>\n",
       "      <th>End_b</th>\n",
       "      <th>Strand_b</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>exon_id</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101237099</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101237099_101238821</td>\n",
       "      <td>128</td>\n",
       "      <td>101237018</td>\n",
       "      <td>101237099</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "      <td>S1PR1</td>\n",
       "      <td>ENST00000305352.7</td>\n",
       "      <td>ENSE00001356737.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101238425</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101238425_101238821</td>\n",
       "      <td>38</td>\n",
       "      <td>101238334</td>\n",
       "      <td>101238425</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "      <td>S1PR1</td>\n",
       "      <td>ENST00000648480.1</td>\n",
       "      <td>ENSE00003837007.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>111477428</td>\n",
       "      <td>111477650</td>\n",
       "      <td>+</td>\n",
       "      <td>1_111477428_111477650</td>\n",
       "      <td>75</td>\n",
       "      <td>111477333</td>\n",
       "      <td>111477428</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000143110.12</td>\n",
       "      <td>C1orf162</td>\n",
       "      <td>ENST00000343534.9</td>\n",
       "      <td>ENSE00000958163.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>111477428</td>\n",
       "      <td>111477725</td>\n",
       "      <td>+</td>\n",
       "      <td>1_111477428_111477725</td>\n",
       "      <td>253</td>\n",
       "      <td>111477333</td>\n",
       "      <td>111477428</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000143110.12</td>\n",
       "      <td>C1orf162</td>\n",
       "      <td>ENST00000343534.9</td>\n",
       "      <td>ENSE00000958163.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>120824146</td>\n",
       "      <td>120824865</td>\n",
       "      <td>+</td>\n",
       "      <td>1_120824146_120824865</td>\n",
       "      <td>9</td>\n",
       "      <td>120823973</td>\n",
       "      <td>120824146</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000273136.8</td>\n",
       "      <td>NBPF26</td>\n",
       "      <td>ENST00000620612.5</td>\n",
       "      <td>ENSE00003709317.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>X</td>\n",
       "      <td>40599741</td>\n",
       "      <td>40600761</td>\n",
       "      <td>+</td>\n",
       "      <td>X_40599741_40600761</td>\n",
       "      <td>371</td>\n",
       "      <td>40599648</td>\n",
       "      <td>40599741</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000182220.15</td>\n",
       "      <td>ATP6AP2</td>\n",
       "      <td>ENST00000638153.1</td>\n",
       "      <td>ENSE00003795580.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>X</td>\n",
       "      <td>40599741</td>\n",
       "      <td>40600781</td>\n",
       "      <td>+</td>\n",
       "      <td>X_40599741_40600781</td>\n",
       "      <td>25</td>\n",
       "      <td>40599648</td>\n",
       "      <td>40599741</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000182220.15</td>\n",
       "      <td>ATP6AP2</td>\n",
       "      <td>ENST00000638153.1</td>\n",
       "      <td>ENSE00003795580.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>X</td>\n",
       "      <td>48575283</td>\n",
       "      <td>48575560</td>\n",
       "      <td>+</td>\n",
       "      <td>X_48575283_48575560</td>\n",
       "      <td>207</td>\n",
       "      <td>48575167</td>\n",
       "      <td>48575283</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000102317.18</td>\n",
       "      <td>RBM3</td>\n",
       "      <td>ENST00000376759.8</td>\n",
       "      <td>ENSE00003606332.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>X</td>\n",
       "      <td>48575283</td>\n",
       "      <td>48576313</td>\n",
       "      <td>+</td>\n",
       "      <td>X_48575283_48576313</td>\n",
       "      <td>15</td>\n",
       "      <td>48575167</td>\n",
       "      <td>48575283</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000102317.18</td>\n",
       "      <td>RBM3</td>\n",
       "      <td>ENST00000376759.8</td>\n",
       "      <td>ENSE00003606332.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>X</td>\n",
       "      <td>48575667</td>\n",
       "      <td>48576313</td>\n",
       "      <td>+</td>\n",
       "      <td>X_48575667_48576313</td>\n",
       "      <td>190</td>\n",
       "      <td>48575560</td>\n",
       "      <td>48575667</td>\n",
       "      <td>+</td>\n",
       "      <td>ENSG00000102317.18</td>\n",
       "      <td>RBM3</td>\n",
       "      <td>ENST00000376759.8</td>\n",
       "      <td>ENSE00003674591.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "+--------------+-----------+-----------+--------------+-------+\n",
       "| Chromosome   | Start     | End       | Strand       | +10   |\n",
       "| (category)   | (int64)   | (int64)   | (category)   | ...   |\n",
       "|--------------+-----------+-----------+--------------+-------|\n",
       "| 1            | 101237099 | 101238821 | +            | ...   |\n",
       "| 1            | 101238425 | 101238821 | +            | ...   |\n",
       "| 1            | 111477428 | 111477650 | +            | ...   |\n",
       "| 1            | 111477428 | 111477725 | +            | ...   |\n",
       "| ...          | ...       | ...       | ...          | ...   |\n",
       "| X            | 40599741  | 40600781  | +            | ...   |\n",
       "| X            | 48575283  | 48575560  | +            | ...   |\n",
       "| X            | 48575283  | 48576313  | +            | ...   |\n",
       "| X            | 48575667  | 48576313  | +            | ...   |\n",
       "+--------------+-----------+-----------+--------------+-------+\n",
       "Stranded PyRanges object has 375 rows and 14 columns from 21 chromosomes.\n",
       "For printing, the PyRanges was sorted on Chromosome and Strand.\n",
       "10 hidden columns: junction_id, counts_total, Start_b, End_b, Strand_b, ... (+ 5 more.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juncs_gr = juncs_gr[juncs_gr.junction_id.isin(clusters.junction_id)]\n",
    "juncs_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/kisaev/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pyranges/tostring2.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([plus, minus])\n",
      "/gpfs/commons/home/kisaev/miniconda3/envs/LeafletSC/lib/python3.10/site-packages/pyranges/tostring2.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([plus, minus])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>junction_id</th>\n",
       "      <th>gene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101237099</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101237099_101238821</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101238425</td>\n",
       "      <td>101238821</td>\n",
       "      <td>+</td>\n",
       "      <td>1_101238425_101238821</td>\n",
       "      <td>ENSG00000170989.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>111477428</td>\n",
       "      <td>111477650</td>\n",
       "      <td>+</td>\n",
       "      <td>1_111477428_111477650</td>\n",
       "      <td>ENSG00000143110.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>111477428</td>\n",
       "      <td>111477725</td>\n",
       "      <td>+</td>\n",
       "      <td>1_111477428_111477725</td>\n",
       "      <td>ENSG00000143110.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>120824146</td>\n",
       "      <td>120824865</td>\n",
       "      <td>+</td>\n",
       "      <td>1_120824146_120824865</td>\n",
       "      <td>ENSG00000273136.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>X</td>\n",
       "      <td>40599741</td>\n",
       "      <td>40600761</td>\n",
       "      <td>+</td>\n",
       "      <td>X_40599741_40600761</td>\n",
       "      <td>ENSG00000182220.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>X</td>\n",
       "      <td>40599741</td>\n",
       "      <td>40600781</td>\n",
       "      <td>+</td>\n",
       "      <td>X_40599741_40600781</td>\n",
       "      <td>ENSG00000182220.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>X</td>\n",
       "      <td>48575283</td>\n",
       "      <td>48575560</td>\n",
       "      <td>+</td>\n",
       "      <td>X_48575283_48575560</td>\n",
       "      <td>ENSG00000102317.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>X</td>\n",
       "      <td>48575283</td>\n",
       "      <td>48576313</td>\n",
       "      <td>+</td>\n",
       "      <td>X_48575283_48576313</td>\n",
       "      <td>ENSG00000102317.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>X</td>\n",
       "      <td>48575667</td>\n",
       "      <td>48576313</td>\n",
       "      <td>+</td>\n",
       "      <td>X_48575667_48576313</td>\n",
       "      <td>ENSG00000102317.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "+--------------+-----------+-----------+--------------+-------+\n",
       "| Chromosome   | Start     | End       | Strand       | +2    |\n",
       "| (category)   | (int64)   | (int64)   | (category)   | ...   |\n",
       "|--------------+-----------+-----------+--------------+-------|\n",
       "| 1            | 101237099 | 101238821 | +            | ...   |\n",
       "| 1            | 101238425 | 101238821 | +            | ...   |\n",
       "| 1            | 111477428 | 111477650 | +            | ...   |\n",
       "| 1            | 111477428 | 111477725 | +            | ...   |\n",
       "| ...          | ...       | ...       | ...          | ...   |\n",
       "| X            | 40599741  | 40600781  | +            | ...   |\n",
       "| X            | 48575283  | 48575560  | +            | ...   |\n",
       "| X            | 48575283  | 48576313  | +            | ...   |\n",
       "| X            | 48575667  | 48576313  | +            | ...   |\n",
       "+--------------+-----------+-----------+--------------+-------+\n",
       "Stranded PyRanges object has 375 rows and 6 columns from 21 chromosomes.\n",
       "For printing, the PyRanges was sorted on Chromosome and Strand.\n",
       "2 hidden columns: junction_id, gene_id"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juncs_coords_unique = juncs_coords_unique[juncs_coords_unique.junction_id.isin(clusters.junction_id)]\n",
    "juncs_coords_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeafletSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
